<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="https://serverascode.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://serverascode.com/" rel="alternate" type="text/html" /><updated>2025-02-18T07:55:03-05:00</updated><id>https://serverascode.com/feed.xml</id><title type="html">Server As Code Dot Com</title><subtitle>A techno-blog for our techno-times</subtitle><entry><title type="html">The Tailscale Kubernetes Operator</title><link href="https://serverascode.com/2025/01/31/tailscale-kubernetes-operator.html" rel="alternate" type="text/html" title="The Tailscale Kubernetes Operator" /><published>2025-01-31T00:00:00-05:00</published><updated>2025-01-31T00:00:00-05:00</updated><id>https://serverascode.com/2025/01/31/tailscale-kubernetes-operator</id><content type="html" xml:base="https://serverascode.com/2025/01/31/tailscale-kubernetes-operator.html"><![CDATA[<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
    <img src="/img/magazine-cards/tailscale-k8s-operator-200w.png" alt="Tailscale Kubernetes Operator" style="max-width: 200px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);" />
    <p><em>Make your Kubernetes networking life easier with the Tailscale Kubernetes operator.</em></p>
</div>

<hr />

<h2 id="tldr">tl;dr</h2>

<p>Modern Kubernetes networking involves multiple complex layers: physical networks, CNI plugins like Calico (handling BGP meshes, VXLAN, IPIP tunnels, and NAT), service meshes, and external access concerns. While the post dives into Calico’s implementation details in a homelab setup—showing how it manages IP pools, BGP peering, and cross-node communication—the <a href="https://tailscale.com/kb/1236/kubernetes-operator">Tailscale Kubernetes operator</a> emerges as a surprisingly straightforward solution for secure service exposure, requiring just a simple annotation to make workloads accessible across your entire tailnet.</p>

<p>Here’s a diagram of my homelab Kubernetes setup, including Tailscale.</p>
<div style="text-align: center; margin: 20px auto;">
    <a href="/img/tailscale-k8s-operator/mermaid-diagram.png" target="_blank">
        <img src="/img/tailscale-k8s-operator/mermaid-diagram-200w.png" alt="Network Diagram" style="max-width: 400px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2); display: block; margin: 0 auto;" />
    </a>
    <p><em>Click image to enlarge</em></p>
</div>

<h2 id="introduction">Introduction</h2>

<p>There are many layers to networking, especially when you add Kubernetes into the mix. In my relatively simple homelab setup, I have a physical network, a Kubernetes network based on Calico, and now I’m adding Tailscale. But there can be more layers, and more complexity.</p>

<p>Kubernetes networking is interesting because one of the early design decisions was that every pod should have its own routable layer 3 IP address. In some ways, this is a much simpler design for networking, just make everything layer 3 routable. Now we can run thousands and thousands of pods without having to worry about broadcast domains.</p>

<p>But in order to use Kubernetes, you have to set up a CNI–a container network interface. Kubernetes doesn’t actually do its own networking, it just uses the CNI plugin. And the CNI is, in many ways, free to implement the network in any way it wants, from straight Layer 3, to BGP meshes, to overlays like VXLAN and IPIP, or a combination of all of those and other things. So yes, each pod has its own IP address, but how that actually works is up to the CNI.</p>

<p>But there’s more!</p>

<ul>
  <li>More interestingly, we still need to “expose” workloads, whether via a load balancer, ingress or other means.</li>
  <li>We have added the concept of service meshes.</li>
  <li>And we know we have the concept of zero trust networking.</li>
  <li>And what if we want to access services in other clusters?</li>
  <li>Or services running in Kubernetes need to access external services?</li>
</ul>

<p>I’m not stating anything new here, Kubernetes is getting quite mature, as has the networking capabilities that we layer on top. There are a lot of interesting options available.</p>

<h2 id="the-tailscale-kubernetes-operator">The Tailscale Kubernetes Operator</h2>

<blockquote>
  <p>Tailscale makes creating software-defined networks easy: securely connecting users, services, and devices. - <a href="https://tailscale.com">https://tailscale.com</a></p>
</blockquote>

<p>First, I’ve written about Tailscale before.</p>

<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px; background-color: #f5f5f5; padding: 20px; border-radius: 5px;">
    <a href="https://serverascode.com/2024/11/23/tailscale-mulladvpn.html">
        <img src="/img/magazine-cards/tailscale-mullvad-200w.png" alt="Tailscale Mullvad" style="max-width: 200px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);" />
    </a>
    <p><em>Also check out my other post about using <a href="https://serverascode.com/2025/01/31/tailscale-kubernetes-operator.html">Tailscale with Kubernetes</a>.</em></p>
</div>

<p>That post is more about building up a safe personal network combined with Mullvad VPN. This post is about securing and building connectivity with <a href="https://tailscale.com/kb/1236/kubernetes-operator">Tailscale’s Kubernetes operator</a>.</p>

<p>Tailscale provides several options for setting up in Kubernetes, and one of them is the <a href="https://tailscale.com/kb/1236/kubernetes-operator">Tailscale Kubernetes Operator</a>, which is what I’ll be using in this post.</p>

<p>But first, let’s get Kubernetes installed.</p>

<h2 id="installing-kubernetes">Installing Kubernetes</h2>

<p>First, I’ll use my Kubernetes installer script, brilliantly named <a href="https://github.com/ccollicutt/install-kubernetes">install-kubernetes</a>, to set up a Kubernetes cluster. It simply installs a simple kubeadm-based cluster on Ubuntu 22.04 virtual machines, adding in Calico as the CNI.</p>

<pre><code class="language-bash">root@ts1:~# git clone https://github.com/ccollicutt/install-kubernetes
Cloning into 'install-kubernetes'...
remote: Enumerating objects: 105, done.
remote: Counting objects: 100% (18/18), done.
remote: Compressing objects: 100% (11/11), done.
remote: Total 105 (delta 12), reused 12 (delta 7), pack-reused 87 (from 1)
Receiving objects: 100% (105/105), 23.90 KiB | 479.00 KiB/s, done.
Resolving deltas: 100% (52/52), done.
root@ts1:~# cd install-kubernetes
root@ts1:~/install-kubernetes# ./install-kubernetes.sh -s
Starting install...
==&gt; Logging all output to /tmp/install-kubernetes-R21z3PlZYv/install.log
Checking Linux distribution
Disabling swap
Removing packages
Installing required packages
Installing Kubernetes packages
Configuring system
Configuring crictl
Configuring kubelet
Configuring containerd
Installing containerd
Starting services
Configuring control plane node...
Initialising the Kubernetes cluster via Kubeadm
Configuring kubeconfig for root and ubuntu users
Installing Calico CNI
==&gt; Installing Calico tigera-operator
==&gt; Installing Calico custom-resources
Waiting for nodes to be ready...
==&gt; Nodes are ready
Checking Kubernetes version...
==&gt; Client version: v1.31.0
==&gt; Server Version: v1.31.0
==&gt; Requested KUBE_VERSION matches the server version.
Installing metrics server
Configuring as a single node cluster
Configuring as a single node cluster
Deploying test nginx pod
Waiting for all pods to be running...
Install complete!

### Command to add a worker node ###
kubeadm join 10.10.10.250:6443 --token &lt;REDACTED&gt; --discovery-token-ca-cert-hash &lt;REDACTED&gt; 
</code></pre>

<p>This gives me an initial Kubernetes node, which is both a control plane and a worker node. Next, I add another worker node, but I won’t show that output here.</p>

<p>So now I’ve got two nodes, <code>ts1</code> and <code>ts2</code>.</p>

<pre><code>$ k get nodes
NAME   STATUS   ROLES           AGE   VERSION
ts1    Ready    control-plane   15h   v1.31.0
ts2    Ready    &lt;none&gt;          15h   v1.31.0
</code></pre>

<h2 id="installing-the-tailscale-kubernetes-operator">Installing the Tailscale Kubernetes Operator</h2>

<h3 id="setting-up-tailscale">Setting up Tailscale</h3>

<p>This includes the following steps (see the <a href="https://tailscale.com/kb/1236/kubernetes-operator">docs</a> for more details):</p>

<ol>
  <li>Setting up an OAuth client ID and secret</li>
  <li>Configuring tags in the ACLs</li>
</ol>

<p><img src="/img/tailscale-k8s-operator/kubernetes-operator-tailscale-docs.png" alt="Kubernetes operator tailscale docs" /></p>

<ul>
  <li>Set up OAuth client ID and secret</li>
</ul>

<p><img src="/img/tailscale-k8s-operator/oauth-clients-tailscale.png" alt="Tailscale OAuth client ID and secret" /></p>

<ul>
  <li>Set up ACL tags</li>
</ul>

<p><img src="/img/tailscale-k8s-operator/access-controls-tailscale.png" alt="Tailscale ACL Tags" /></p>

<ul>
  <li>See the results in machines once the operator is installed and some workloads are created (note that this is after the operator is installed, and some workloads are created)</li>
</ul>

<p><img src="/img/tailscale-k8s-operator/machines-tailscale.png" alt="Machines" /></p>

<h3 id="install-into-kubernetes-with-helm">Install into Kubernetes with Helm</h3>

<p>I’ll show you my <a href="https://github.com/casey/just">justfile</a> commands for installation.</p>

<pre><code>add-tailscale-helm:
    helm repo add tailscale https://pkgs.tailscale.com/helmcharts
    helm repo update

install-tailscale-operator:
    helm upgrade \
        --install \
        tailscale-operator \
        tailscale/tailscale-operator \
        --namespace=tailscale \
        --create-namespace \
        --set-string oauth.clientId="${TS_CLIENT_ID}" \
        --set-string oauth.clientSecret="${TS_CLIENT_SECRET}" \
        --wait
</code></pre>

<p>Thanks to Helm, very simple to install.</p>

<pre><code>$ just install-tailscale-operator
</code></pre>

<h2 id="what-does-this-network-look-like">What Does This Network Look Like?</h2>

<p>In this section we’ll go over the layers. To visualize those layers, here’s a diagram of my homelab setup.</p>

<div class="bg-amber-50 border-l-4 border-amber-500 p-4 my-4">
  <p class="text-amber-700"><strong>Disclaimer:</strong> This is a basic diagram of my homelab setup and is not completely accurate. Please refer to official Tailscale and Calico and Kubernetes documentation!</p>
</div>

<p><a href="/img/tailscale-k8s-operator/mermaid-diagram.png" target="_blank"><img src="/img/tailscale-k8s-operator/mermaid-diagram.png" alt="Homelab networking diagram" target="_blank" /></a></p>

<h3 id="physical-networking">Physical Networking</h3>

<p>The physical networking is straightforward: the two nodes/vms are on the same VLAN, and have direct access to each other. (I use <a href="https://serverascode.com/2024/10/19/incus-installation-and-use.html">Incus</a> to manage my VMs.)</p>

<h3 id="calico-networking">Calico Networking</h3>

<p>The Calico configuration is what you get by default. Calico is VERY configurable, and you can do a lot of complex things with it, but this is the default deployment.</p>

<pre><code class="language-bash">$ kubectl get ippool -o yaml
apiVersion: v1
items:
- apiVersion: projectcalico.org/v3
  kind: IPPool
  metadata:
    creationTimestamp: "2025-01-31T23:51:56Z"
    name: default-ipv4-ippool
    resourceVersion: "891"
    uid: 15bc140e-701b-4cb9-aea8-82e74925b997
  spec:
    allowedUses:
    - Workload
    - Tunnel
    blockSize: 26
    cidr: 192.168.0.0/16
    ipipMode: Never
    natOutgoing: true
    nodeSelector: all()
    vxlanMode: CrossSubnet
kind: List
metadata:
  resourceVersion: ""
</code></pre>

<p>or…</p>

<pre><code class="language-bash"># calicoctl get ippool default-ipv4-ippool -oyaml
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
  creationTimestamp: "2025-01-31T23:51:56Z"
  name: default-ipv4-ippool
  resourceVersion: "891"
  uid: 15bc140e-701b-4cb9-aea8-82e74925b997
spec:
  allowedUses:
  - Workload
  - Tunnel
  blockSize: 26
  cidr: 192.168.0.0/16
  ipipMode: Never
  natOutgoing: true
  nodeSelector: all()
  vxlanMode: CrossSubnet
</code></pre>

<p>IP address management is handled by Calico.</p>

<pre><code># calicoctl ipam show --show-blocks
+----------+--------------------+-----------+------------+--------------+
| GROUPING |        CIDR        | IPS TOTAL | IPS IN USE |   IPS FREE   |
+----------+--------------------+-----------+------------+--------------+
| IP Pool  | 192.168.0.0/16     |     65536 | 15 (0%)    | 65521 (100%) |
| Block    | 192.168.131.64/26  |        64 | 8 (12%)    | 56 (88%)     |
| Block    | 192.168.153.128/26 |        64 | 7 (11%)    | 57 (89%)     |
+----------+--------------------+-----------+------------+--------------+
</code></pre>

<p>Default settings:</p>

<ul>
  <li>VXLAN mode is set to CrossSubnet, meaning that Calico will only use VXLAN encapsulation when pods are communicating across different subnets.</li>
  <li>IPIP mode is set to Never, which means that IPIP tunneling is not used.</li>
  <li>The network CIDR is 192.168.0.0/16 with a block size of 26, giving 62 usable IPs in each block as managed by Calico.</li>
  <li><code>natOutgoing: true</code> means that outgoing traffic is NATed to the external IP address of the node.</li>
</ul>

<p>So…</p>

<ul>
  <li>Nodes communicate BGP routes over their physical network (10.10.x.x)</li>
  <li>Nodes get IPs from the configured pool (192.168.0.0/16)</li>
  <li>The physical network handles the actual packet delivery between the nodes</li>
  <li>There is NAT involved (multiple NATs actually)</li>
</ul>

<pre><code class="language-bash"># calicoctl ipam show
+----------+----------------+-----------+------------+--------------+
| GROUPING |      CIDR      | IPS TOTAL | IPS IN USE |   IPS FREE   |
+----------+----------------+-----------+------------+--------------+
| IP Pool  | 192.168.0.0/16 |     65536 | 15 (0%)    | 65521 (100%) |
+----------+----------------+-----------+------------+--------------+
# calicoctl node status
Calico process is running.

IPv4 BGP status
+--------------+-------------------+-------+----------+-------------+
| PEER ADDRESS |     PEER TYPE     | STATE |  SINCE   |    INFO     |
+--------------+-------------------+-------+----------+-------------+
| 10.10.10.246 | node-to-node mesh | up    | 23:55:06 | Established |
+--------------+-------------------+-------+----------+-------------+

IPv6 BGP status
No IPv6 peers found.
</code></pre>

<p>There are only two nodes, so the BGP mesh is, well, as small as it gets.</p>

<p>We can see all the pods and such and what hosts they are on, IPs, etc.</p>

<pre><code class="language-bash">$ just show-pod-details 
POD NAME                    POD IP          NODE NAME        NODE IP
-------------------------  --------------  ---------------  --------------
calico-apiserver-64497c8b94-2xlqq          192.168.131.72    ts1    10.10.10.250
calico-apiserver-64497c8b94-c7px8          192.168.131.71    ts1    10.10.10.250
calico-kube-controllers-7d868b8f66-85ldw   192.168.131.67    ts1    10.10.10.250
calico-node-b68ck                          10.10.10.246      ts2    10.10.10.246
calico-node-j5sw5                          10.10.10.250      ts1    10.10.10.250
calico-typha-764c8bcd98-pwnf4              10.10.10.250      ts1    10.10.10.250
csi-node-driver-2bg5q                      192.168.131.70    ts1    10.10.10.250
csi-node-driver-6hs69                      192.168.153.129   ts2    10.10.10.246
hello-tailscale-expose-74c4485894-xms5d    192.168.153.137   ts2    10.10.10.246
hello-tailscale-5c8bf6665c-7lqvj           192.168.153.131   ts2    10.10.10.246
coredns-6f6b679f8f-knnlg                   192.168.131.65    ts1    10.10.10.250
coredns-6f6b679f8f-sdrp6                   192.168.131.68    ts1    10.10.10.250
etcd-ts1                                   10.10.10.250      ts1    10.10.10.250
kube-apiserver-ts1                         10.10.10.250      ts1    10.10.10.250
kube-controller-manager-ts1                10.10.10.250      ts1    10.10.10.250
kube-proxy-gm8rh                           10.10.10.246      ts2    10.10.10.246
kube-proxy-lq5p9                           10.10.10.250      ts1    10.10.10.250
kube-scheduler-ts1                         10.10.10.250      ts1    10.10.10.250
metrics-server-5f94f4d4fd-rr92x            192.168.131.64    ts1    10.10.10.250
operator-6999975fd7-dxvv5                  192.168.153.130   ts2    10.10.10.246
ts-hello-tailscale-expose-db59d-0          192.168.153.136   ts2    10.10.10.246
ts-hello-tailscale-z5dfr-0                 192.168.153.133   ts2    10.10.10.246
tigera-operator-b974bcbbb-hrzv9            10.10.10.250      ts1    10.10.10.250
</code></pre>

<h3 id="tailscale-networking">Tailscale Networking</h3>

<p>Tailscale uses Wireguard to create a secure network.</p>

<blockquote>
  <p>Tailscale is built on top of WireGuard; we think very highly of it - <a href="https://tailscale.com/compare/wireguard">https://tailscale.com/compare/wireguard</a></p>
</blockquote>

<p>Tailscale takes Wireguard quite a bit further, dealing with all the other issues around modern networks, e.g. NAT (which can be brutal to deal with), and adding Access Control Lists (ACLs) and other features.</p>

<blockquote>
  <p>Tailscale takes care of on-demand NAT traversal so that devices can talk to each other directly in most circumstances, without manual configuration. When NAT traversal fails, Tailscale relays encrypted traffic, so that devices can always talk to each other, albeit with higher latency in that case. There is no need to modify firewalls or routers; any devices that can reach the internet can reach each other. (Tailscale traffic between two devices on the same LAN does not leave that LAN.) - <a href="https://tailscale.com/compare/wireguard">https://tailscale.com/compare/wireguard</a></p>
</blockquote>

<p>In the Kubernetes deployment we have a proxy pod that is setup for each exposed service by the operator–at least that is the way that I understand it.</p>

<pre><code>$ k get pods -n tailscale 
NAME                                READY   STATUS    RESTARTS   AGE
operator-6999975fd7-dxvv5           1/1     Running   0          140m
ts-hello-tailscale-expose-db59d-0   1/1     Running   0          80m
ts-hello-tailscale-z5dfr-0          1/1     Running   0          119m
</code></pre>

<p>The <code>ts-hellow-tailscale*</code> workloads are running in their own namespaces, above are the tailscale pods for those workloads.</p>

<h2 id="accessing-workloads-with-tailscale">Accessing Workloads With Tailscale</h2>

<p>Here’s some justfile commands to curl the hello-tailscale service.</p>

<p>Note that this workload is using the Tailscale annotation to expose the service, but you can also use the Tailscale LoadBalancer service type, and a couple of other options I believe.</p>

<pre><code class="language-bash">deploy-tailscale-hello-with-expose:
    #!/usr/bin/env bash
    set -euxo pipefail
    kubectl apply -f - &lt;&lt;'EOF'
    apiVersion: v1
    kind: Namespace
    metadata:
      name: hello-tailscale-expose
    ---
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: nginx-index-html
      namespace: hello-tailscale-expose
    data:
      index.html: |
        &lt;h1&gt;Hello from Tailscale Expose!&lt;/h1&gt;
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: hello-tailscale-expose
      namespace: hello-tailscale-expose
      labels:
        app: hello-tailscale-expose
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: hello-tailscale-expose
      template:
        metadata:
          labels:
            app: hello-tailscale-expose
        spec:
          containers:
            - name: hello-tailscale-expose
              image: nginx:latest
              ports:
                - containerPort: 80
              volumeMounts:
                - name: nginx-index
                  mountPath: /usr/share/nginx/html
          volumes:
            - name: nginx-index
              configMap:
                name: nginx-index-html
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: hello-tailscale-expose
      namespace: hello-tailscale-expose
      annotations:
        tailscale.com/expose: "true"
    spec:
      selector:
        app: hello-tailscale-expose
      ports:
        - port: 80
          targetPort: 80
    EOF
</code></pre>

<p>And we can easily access that service from my workstation, which is on the tailnet!</p>

<div class="bg-blue-50 border-l-4 border-blue-500 p-4 my-4">
  <p class="text-blue-700">📝 Note that one of these workloads I specified a loadbalancer for, and for the other I used the Tailscale expose annotation.</p>
</div>

<pre><code>$ tailscale status | grep hello
100.80.241.127  hello-tailscale-expose-hello-tailscale-expose tagged-devices linux   -
100.85.85.53    hello-tailscale-hello-tailscale tagged-devices linux   idle, tx 532 rx 316
100.101.102.103 hello.ts.net         hello@       linux   -
$ curl hello-tailscale-hello-tailscale
&lt;h1&gt;Hello from Tailscale LoadBalancer!&lt;/h1&gt;
$ curl hello-tailscale-expose-hello-tailscale-expose
&lt;h1&gt;Hello from Tailscale Expose!&lt;/h1&gt;
</code></pre>

<p>And we can see that in this screenshot as well.</p>

<p><img src="/img/tailscale-k8s-operator/hello-tailscale.png" alt="Hello from Tailscale LoadBalancer" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>Tailscale solves a lot of problems for me, especially when it comes to using containers. Networking has become very complex. For example, in the past in my homelab I’d set up <a href="https://metallb.io/">MetalLB</a> to create a load balancer for applications. MetalLB is an amazing piece of technology (thank you to those that built and maintain it!), but I’d be managing IPs and trying to remember which ranges I’d allowed the loadbalancer to use, and inevitably I’d forget. Never mind that those workloads wouldn’t be accessible from my laptop–when I was at home on my workstation, sure, no problem, but when I was on the road I’d have Tailnet but no Kubernetes access. Now I have that too, plus the ability to use ACLs to control access to my Kubernetes cluster. Or, potentially, I can deploy apps that I will use, and be able to access them from my phone too. Very nice! Now I can deploy apps into Kubernetes and use them from any of my devices.</p>

<div class="bg-green-50 border-l-4 border-green-500 p-4 my-4">
  <p class="text-green-700">📝 Note that there are some things to think about when using Kubernetes, NAT, and Tailscale. Best to read this <a href="https://tailscale.com/blog/kubernetes-direct-connections" class="underline">Tailscale blog post</a> for more details.</p>
</div>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><a href="https://tailscale.com/learn/managing-access-to-kubernetes-with-tailscale">How to Secure Kubernetes Access with Tailscale</a></li>
  <li><a href="https://tailscale.com/blog/kubernetes-direct-connections">Kubernetes, direct connections, and you</a></li>
  <li><a href="https://tailscale.com/blog/how-tailscale-works">How Tailscale Works</a></li>
  <li><a href="https://tailscale.com/blog/how-nat-traversal-works">How NAT Traversal Works</a></li>
  <li><a href="https://www.youtube.com/watch?v=7EoCa9HP9Bc&amp;t=3742s">Tailscale Webinar - NAT Traversal explained with Lee Briggs</a></li>
  <li><a href="https://docs.tigera.io/calico/latest/networking/configuring/vxlan-ipip">Calico Overlay networking</a></li>
</ul>

<h2 id="ps-mermaid-diagram-code">PS. Mermaid Diagram Code</h2>

<p>Again, not a perfect diagram, but it’s a good start.</p>

<pre><code>graph TB
    subgraph Disclaimer[**This is a basic diagram of my homelab setup and may contain inaccuracies.&lt;br&gt;Please refer to official Tailscale documentation.**]
        style Disclaimer fill:#fff,stroke:#f66,stroke-width:2px,stroke-dasharray: 5 5
    end

    subgraph Physical Network
        DHCP[DHCP Server]
        VLAN[VLAN Network]
        DHCP --&gt; VLAN
    end

    subgraph Kubernetes Cluster
        subgraph Kubernetes Nodes
            Node1[Node ts1&lt;br&gt;Control Plane + Worker]
            Node2[Node ts2&lt;br&gt;Worker]
            VLAN --&gt; Node1
            VLAN --&gt; Node2
        end

        subgraph Calico Networking
            BGPBGP Mesh&lt;br&gt;(Node to Node)
            IPPOOL[IP Pool&lt;br&gt;natOutgoing: true]
            Node1 &lt;--&gt; BGP
            Node2 &lt;--&gt; BGP
            BGP --&gt; IPPOOL
            Pod1[Pods on ts1]
            Pod2[Pods on ts2]
            IPPOOL --&gt; Pod1
            IPPOOL --&gt; Pod2
            Pod1 -.-&gt;|NAT| INTERNET
            Pod2 -.-&gt;|NAT| INTERNET
        end

        subgraph Example Service
            HELLO[hello-tailscale-expose]
            TS_HELLO[ts-hello-tailscale-expose&lt;br&gt;Tailscale Proxy Pod]
            HELLO --&gt; TS_HELLO
        end

        Pod1 --&gt; TS_OP
        Pod2 --&gt; TS_OP

        subgraph Tailscale Layer
            TS_OP[Tailscale Operator&lt;br&gt;Pod]
            TS_OP --&gt; TS_HELLO
        end
    end

    subgraph Tailnet Devices
        LAPTOP[Laptop&lt;br&gt;Tailscale Client]
    end

    TS_CTRL[Tailscale Control Plane&lt;br&gt;Cloud Service]
    INTERNET((Internet))
    
    %% Encrypted connections as dotted lines
    TS_CTRL -.- TS_OP
    TS_CTRL -.- LAPTOP
    LAPTOP -.- TS_HELLO
    
    classDef physical fill:#f9f,stroke:#333,stroke-width:2px
    classDef calico fill:#bbf,stroke:#333,stroke-width:2px
    classDef tailscale fill:#bfb,stroke:#333,stroke-width:2px
    classDef k8s fill:#fff,stroke:#326CE5,stroke-width:2px
    classDef device fill:#fdb,stroke:#333,stroke-width:2px
    classDef service fill:#dfd,stroke:#333,stroke-width:2px
    
    class DHCP,VLAN physical
    class BGP,IPPOOL,Pod1,Pod2 calico
    class TS_CTRL,TS_OP tailscale
    class Kubernetes_Cluster k8s
    class LAPTOP device
    class HELLO,TS_HELLO service
</code></pre>]]></content><author><name></name></author><summary type="html"><![CDATA[Make your Kubernetes networking life easier with the Tailscale Kubernetes operator.]]></summary></entry><entry><title type="html">Malicious Codes and Where to Find Them</title><link href="https://serverascode.com/2025/01/30/malcious-codes-and-where-to-find-them.html" rel="alternate" type="text/html" title="Malicious Codes and Where to Find Them" /><published>2025-01-30T00:00:00-05:00</published><updated>2025-01-30T00:00:00-05:00</updated><id>https://serverascode.com/2025/01/30/malcious-codes-and-where-to-find-them</id><content type="html" xml:base="https://serverascode.com/2025/01/30/malcious-codes-and-where-to-find-them.html"><![CDATA[<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
    <img src="/img/magazine-cards/malicious-code-200w.png" alt="Malicious code" style="max-width: 200px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);" />
    <p><em>tldr; Malicious code is everywhere, but it's dangerous and hard to find. Here are some of the ways one might find it, or create it.</em></p>
</div>

<hr />

<div class="disclaimer" style="background-color: #fff3e0; border-left: 4px solid #ff9800; padding: 15px; margin: 20px 0;">
    <p style="margin: 0;"><span style="font-size: 1.2em;">⚠️</span> <strong>Disclaimer:</strong> <i>Malicious code (MC) analysis is important for cybersecurity, but it requires careful handling. We tend to keep it hidden, but it's out there (unfortunately, we also tend to find it when we least expect it). When performing malicious code analysis, proper security protocols are critical--including the use of isolated virtual machines, detonation zones, secure test environments, etc. to prevent accidental execution or system compromise.</i></p>
</div>

<h2 id="introduction">Introduction</h2>

<p><img src="/img/malicious-code-circular.png" alt="Malicious code" /></p>

<p>I’ve got a project where I need malicious code to test with. Not to break into systems, but to test software that is supposed to detect malicious code.</p>

<p>BUT…malicious code doesn’t grow on (binary) trees, it’s hard to find online and in Github repositories, although there seems to be a lot of it.</p>

<p>Example: <a href="https://arstechnica.com/security/2024/02/github-besieged-by-millions-of-malicious-repositories-in-ongoing-attack/">Github besieged by millions of malicious repositories in ongoing attack</a></p>

<p><img src="/img/malicious-code1.png" alt="Malicious code" /></p>

<h2 id="options-for-finding-malicious-code">Options for Finding Malicious Code</h2>

<ol>
  <li>Write it yourself
    <ul>
      <li>Possibly using <a href="https://github.com/Yara-Rules/rules">YARA rules</a> to reverse engineer test code</li>
    </ul>
  </li>
  <li>Find it on the “Internet”, e.g.
    <ul>
      <li>Find open caches of MC</li>
      <li>Go to the backwaters of the internet</li>
      <li>Search Github for specific known MC code patterns</li>
    </ul>
  </li>
  <li>Use a large language model (LLM) to generate it</li>
</ol>

<p>Each of these has its own set of problems.</p>

<ol>
  <li>You can write MC, but it won’t be as diverse, and it won’t look like real MC.</li>
  <li>Finding MC on the internet is difficult, and sometimes you end up in the various backwaters of the internet, i.e. the pages that don’t show up in search results.</li>
  <li>Most LLMs will refuse to generate MC, or will generate code that is so obviously MC that it is unusable.</li>
</ol>

<h2 id="finding-it-on-the-internet">Finding it on the Internet</h2>

<p>An example: <a href="https://github.com/ytisf/theZoo">theZoo</a>, which fits well with my monster theme. As I said, it’s hard to find MC on the internet, but there must be collections of it out there, and this is one of them.</p>

<blockquote>
  <p>theZoo is a project created to make the possibility of malware analysis open and available to the public. Since we have found out that almost all versions of malware are very hard to come by in a way which will allow analysis, we have decided to gather all of them for you in an accessible and safe way. theZoo was born by Yuval tisf Nativ and is now maintained by Shahak Shalev. - <a href="https://github.com/ytisf/theZoo">theZoo</a></p>
</blockquote>

<p><img src="/img/malicious-code-the-zoo.png" alt="The Zoo of Malicious Code" /></p>

<h3 id="searching-github">Searching Github</h3>

<p>Topics:</p>

<p><img src="/img/malicious-code-searching-github.png" alt="Searching Github" /></p>

<p>Searching for patterns with Sourcegraph:</p>

<p><img src="/img/malicious-code-sourcegraph.png" alt="Searching with Sourcegraph" /></p>

<p>There is of course much more that could be done here, these are just a few examples.</p>

<h2 id="use-a-large-language-model-llm">Use a Large Language Model (LLM)</h2>

<p>LLMs are good at generating code, but they usually have a lot of guardrails and other restrictions that prevent them from generating code that is actually malicious. There are ways to trick them into generating MC, but it’s probably against the terms of service of the LLM vendor, and it’s extra work.</p>

<p>Here’s a simple example with Claude, just to show the standard guardrail response.</p>

<p><img src="/img/whiterabbitneo-claude.png" alt="Claude" /></p>

<p>However, if we had an LLM without all the guardrails, and perhaps even trained in malicious code, we would be able to generate more realistic malicious code.</p>

<p>Enter White Rabbit Neo.</p>

<blockquote>
  <p>WhiteRabbitNeo is a Generative AI Large Language Model (LLM) designed to support DevSecOps professionals in use cases for offensive and defensive cybersecurity, secure infrastructure design and automation, and more…While the foundation AI models (from OpenAI, Anthropic, Google, and Meta) censor their outputs for many security use cases, WhiteRabbitNeo is uncensored and trained to act like a modern adversary. It has a deep knowledge of threat intelligence, software engineering, even infrastructure as code, making it ideally suited for DevSecOps tasks and offloading tedium. - <a href="https://whiterabbitneo.com/">White Rabbit Neo</a></p>
</blockquote>

<p><img src="/img/whiterabbitneo-login.png" alt="White Rabbit Neo" /></p>

<p>We can ask it to generate some malicious code.</p>

<p><img src="/img/whiterabbitneo-2.png" alt="White Rabbit Neo" /></p>

<p>Well, what it generates isn’t that great, but at least it provides something. One could imagine what nation states and other large, resourceful organisations are doing to train LLMs to generate more realistic malicious code, the caches of MC they have, the resources to train and fine-tune LLMs–they could potentially come up with some interesting MC. (Although, again, code quality, level of deception and sophistication would still be a problem, even now).</p>

<h2 id="conclusion">Conclusion</h2>

<p>This is just a brief look at how one might track down some MC/malware to test with.</p>

<p>I find the lack of examples of malicious code really interesting–how do we as an industry get better at stopping, or at least detecting, malicious code without a lot of public examples? Obviously, the reason is that we don’t want to teach attackers how to write malicious code (that said, I think they are still learning). Of course, this problem has existed almost since we invented programming, and nothing is likely to change, which is fine–it’s just an interesting problem. I’m not suggesting we make it easier for attackers to write malicious code by providing them with more examples–just that “hey, it’s an interesting problem space”.</p>

<div class="callout" style="background-color: #e8f5e9; border-left: 4px solid #4caf50; padding: 15px; margin: 20px 0;">
    <p style="margin: 0;"><strong>🤔</strong> One question I have is with regard to LLMs is: Will LLMs trained on public source code repositories that do NOT contain malicious code be able to produce code that is secure? Without the inverse example of secure code?</p>
</div>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><a href="https://arstechnica.com/security/2024/02/github-besieged-by-millions-of-malicious-repositories-in-ongoing-attack/">GitHub “besieged” by malware repositories and repo confusion: Why you’ll be ok</a></li>
  <li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949524">A Comprehensive Review on Malware Detection Approaches</a></li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[tldr; Malicious code is everywhere, but it's dangerous and hard to find. Here are some of the ways one might find it, or create it.]]></summary></entry><entry><title type="html">Python Program Distribution and Installation Methods</title><link href="https://serverascode.com/2024/12/21/python-installation-methods.html" rel="alternate" type="text/html" title="Python Program Distribution and Installation Methods" /><published>2024-12-21T00:00:00-05:00</published><updated>2024-12-21T00:00:00-05:00</updated><id>https://serverascode.com/2024/12/21/python-installation-methods</id><content type="html" xml:base="https://serverascode.com/2024/12/21/python-installation-methods.html"><![CDATA[<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
    <img src="/img/magazine-cards/python-install-distribute-200w.png" alt="Tailscale Mullvad" style="max-width: 200px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);" />
    <p><em>🐍 tldr; There are many methods to distribute and install Python programs. Here are some of the ways I've tinkered with recently. Recommendation: in most cases, use pipx. 🔧</em></p>
</div>

<hr />

<div class="disclaimer" style="background-color: #fff3e0; border-left: 4px solid #ff9800; padding: 15px; margin: 20px 0;">
    <p style="margin: 0;"><span style="font-size: 1.2em;">⚠️</span> <strong>Disclaimer:</strong> I'm not a Python expert, I've just been writing more Python lately and trying to figure out how best to distribute it. There are several fascinating and useful ways to distribute Python programs, and I've tried a few of them, some successfully, some not so much.</p>
</div>

<h2 id="introduction">Introduction</h2>

<p>I like Python. I’m not sure why…maybe because it seems the closest programming language to English, or maybe because it’s so flexible that you can be messy with it. A lot of people dislike it because it’s not typed, and because you can be messy with it–one can write some pretty unstructured Python code. Also, it doesn’t compile into a single binary. I think that is part of the reason why Go has gained a lot of traction, and now, in a similar vein, we have Rust too. Another problem is that you have to deal with Python versions on the machine where the application is installed. It might be nice to distribute the Python runtime with the application.</p>

<p>So, problems to solve with distributing Python programs, at least by default:</p>

<ol>
  <li>You don’t have a single binary….instead you have an entrypoint into a bunch of Python code and dependencies</li>
  <li>You don’t have a single Python version embedded…you have to deal with all kinds of different system versions</li>
  <li>You typically have a lot of dependencies, Python has a lot of great libraries to take advantage of</li>
  <li>Some dependencies need to be compiled, netifaces as an example, so sometimes you might need a massive toolchain to build them, which makes the user experience a bit more complex (though Python Wheels help with this)</li>
</ol>

<p>This led me to try a few different ways to distribute Python programs that might help with these problems. So far there have been five or so ways I’ve tinkered with to distribute Python programs.</p>

<ol>
  <li>AppImage - <em>NOTE: Didn’t get this working</em></li>
  <li>PyInstaller - <em>This did work and created a nice binary</em></li>
  <li>Pip</li>
  <li>Installer script</li>
  <li>Pipx - <em>Probably the best choice for most situations</em></li>
</ol>

<h2 id="installation-and-distribution-methods">Installation and Distribution Methods</h2>

<h3 id="appimage">AppImage</h3>

<p><a href="https://appimage.org/">AppImage</a> is a very interesting idea, but I couldn’t get it working with my Python application.</p>

<p>From the AppImage website:</p>

<blockquote>
  <p>“As a user, I want to download an application from the original author, and run it on my Linux desktop system just like I would do with a Windows or Mac application.”</p>
</blockquote>

<blockquote>
  <p>“As an application author, I want to provide packages for Linux desktop systems, without the need to get it ‘into’ a distribution and without having to build for gazillions of different distributions.”</p>
</blockquote>

<p>I tinkered with AppImage for a while, but ended up just using PyInstaller. AppImage can package anything, whereas something like PyInstaller is more specific to Python applications. I think this is what tripped me up.</p>

<p>I’ll come back to AppImage later as I think it’s a great idea, and I have applications I use which are distributed as AppImages–just download, mark as executable and run, all in one file.</p>

<h3 id="pyinstaller">PyInstaller</h3>

<blockquote>
  <p>PyInstaller bundles a Python application and all its dependencies into a single package. The user can run the packaged app without installing a Python interpreter or any modules. PyInstaller supports Python 3.8 and newer, and correctly bundles many major Python packages such as numpy, matplotlib, PyQt, wxPython, and others. - <a href="https://pyinstaller.org/en/stable/">PyInstaller</a></p>
</blockquote>

<p>There are a few ways to get a binary out of a Python program. PyInstaller is one of them, and this is the method that seems to work best for me.</p>

<p>Here I build a nice single binary that I can distribute.</p>

<pre><code class="language-bash">pyinstaller \
            --clean \
            --onefile \
            --name coolprog \
            --workpath pyinstaller-build \
            --distpath dist \
            --hidden-import yaml \
            --hidden-import netifaces \
            --hidden-import redis \
            --hidden-import coolprog.cli \
            src/coolprog_main.py
</code></pre>

<p>This created a nice relatively small binary.</p>

<pre><code class="language-bash">du -hsc dist/coolprog
16M	dist/coolprog
16M	total
</code></pre>

<p>All you have to do is distribute the binary! Having a single binary that works, that contains the Python runtime is amazing and feels like magic.</p>

<p>One issue that I have is that apparently sometimes you have to give it some hints regarding the dependencies, e.g. <code>--hidden-import</code>. I’m not clear on how you would know what hints to give.</p>

<p>Benefits:</p>

<ul>
  <li>Everything in one binary</li>
  <li>This includes the Python runtime as well!</li>
  <li>And all the application dependencies</li>
</ul>

<h3 id="pip">Pip</h3>

<p>Pip is the Python package manager. It’s what you typically use to install Python packages. If you’ve used Python, you’ve probably used pip.</p>

<p>A few points:</p>

<ul>
  <li>pip installs your application and dependencies from pypi.org</li>
  <li>Anyone (yes anyone) can sign up for a PyPI account and upload their own packages (which is amazing in itself!)</li>
  <li>There is also a test PyPI server, which is useful for testing</li>
</ul>

<p>Once you’ve signed up for a PyPI account, setup your application, you can simply upload it to PyPI with something like twine, and then once it is uploaded, you can install it with pip.</p>

<pre><code class="language-bash">pip install coolprog
</code></pre>

<p>However, in modern Linux distributions, you will get this kind of message:</p>

<pre><code class="language-bash">ubuntu@coolprog-test:~$ pip install coolprog
error: externally-managed-environment

× This environment is externally managed
╰─&gt; To install Python packages system-wide, try apt install
    python3-xyz, where xyz is the package you are trying to
    install.
    
    If you wish to install a non-Debian-packaged Python package,
    create a virtual environment using python3 -m venv path/to/venv.
    Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make
    sure you have python3-full installed.
    
    If you wish to install a non-Debian packaged Python application,
    it may be easiest to use pipx install xyz, which will manage a
    virtual environment for you. Make sure you have pipx installed.
    
    See /usr/share/doc/python3.12/README.venv for more information.

note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.
</code></pre>

<p>With this in mind, you will likely want to use pipx instead of pip as you don’t want to mess with the system Python, say for example by breaking it during the installation of your application. That would not make you unpopular and would provide a poor user experience.</p>

<h3 id="pipx">Pipx</h3>

<p><a href="https://github.com/pypa/pipx">Pipx</a> is a tool for installing and running Python applications in isolated environments. It’s like pip but specifically for Python applications rather than libraries.</p>

<p>The key benefits of pipx are:</p>

<ol>
  <li>It installs each application in its own isolated virtual environment, preventing dependency conflicts between different applications</li>
  <li>It makes Python applications available globally on your system while keeping their dependencies contained</li>
  <li>It’s easy to install, upgrade, and uninstall applications without affecting other Python tools</li>
</ol>

<div style="background-color: #f0f7fb; border-left: solid 4px #3498db; margin: 12px 0; padding: 12px;">
<p><strong>Nice feature:</strong> Pipx provides a clean installation experience - you don't get a big stream of text output showing the tens of complex dependencies that are being installed.</p>
</div>

<p>Here is an example of installing a Python application with pipx:</p>

<pre><code class="language-bash">pipx install coolprog
</code></pre>

<p>e.g. output:</p>

<pre><code class="language-bash">ubuntu@coolprog-test:~$ pipx install coolprog
  installed package coolprog 0.2.0, installed using Python 3.12.3
  These apps are now globally available
    - coolprog
⚠️  Note: '/home/ubuntu/.local/bin' is not on your PATH environment variable. These apps will
    not be globally accessible until your PATH is updated. Run `pipx ensurepath` to
    automatically add it, or manually modify your PATH in your shell's config file (i.e.
    ~/.bashrc).
done! ✨ 🌟 ✨
</code></pre>

<p>So, just add it to your path and you’re good to go.</p>

<pre><code class="language-bash">ubuntu@coolprog-test:~$ pipx ensurepath
Success! Added /home/ubuntu/.local/bin to the PATH environment variable.

Consider adding shell completions for pipx. Run 'pipx completions' for instructions.

You will need to open a new terminal or re-login for the PATH changes to take effect.

Otherwise pipx is ready to go! ✨ 🌟 ✨
</code></pre>

<p>Nice!</p>

<h3 id="installer-script">Installer Script</h3>

<p>Working with installer scripts was my first approach before moving to PyInstaller or pipx. The classic <code>curl | bash</code> installation method, while discouraged for security reasons, offers simplicity that some people appreciate. The challenge lies in creating an installer script that provides both convenience and a great user experience. You need to consider how the installation impacts the user’s system–what gets installed where, and how it interacts with existing components, etc., etc.</p>

<p>In the script I eventually settled on installing the application in its own Python virtual environment, which ironically ended up being quite similar to pipx’s approach. This makes sense, as isolated environments help avoid dependency conflicts while maintaining a clean, manageable installation. Sure you have a bit more complexity in the number of virtual environments you have to manage, but if there is an abstraction managing it, e.g. pipx, then it’s doable.</p>

<p>In the end, an installer script might make sense, but if pipx will work, it may be best to simply use pipx.</p>

<h3 id="other-methods">Other Methods</h3>

<p>I didn’t try any of these, but some other methods I’ve seen:</p>

<ul>
  <li>Cx_Freeze</li>
  <li>Flatpak</li>
  <li>Py2Exe</li>
  <li>bbfreeze</li>
  <li>py2app</li>
  <li>PyOxidizer???</li>
  <li>Nuitka???</li>
  <li>Docker</li>
  <li>Shiv</li>
  <li>Pipenv</li>
</ul>

<h2 id="and-probably-many-more-some-of-which-are-new-and-some-of-which-are-getting-long-in-the-tooth">And probably many more, some of which are new, and some of which are getting long in the tooth.</h2>
<h2 id="conclusion">Conclusion</h2>

<p>Distributing Python applications isn’t easy. You are installing something into someone’s computer, or server, and you have to make sure it works, that it isn’t going to break their system or their Python environment, and that it is as easy as possible to install. But doing all that is more difficult than it sounds. Though, having now discovered pipx, I think it is the best choice for most situations.</p>

<p>I find all the work outside of writing code for an application to be much, much more complex than writing the code itself, and I’ve written about it <a href="/2024-10-25-pain-of-programming.html">here</a>.</p>

<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
    <img src="/img/magazine-cards/thousand-cuts-200w.png" alt="Death by a Thousand Cuts" style="max-width: 200px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);" />
    <p><em>🤔 Related: Check out my post about <a href="https://serverascode.com/2024/10/25/pain-of-programming.html">the pain points in programming</a> beyond just writing code. 😅</em></p>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[🐍 tldr; There are many methods to distribute and install Python programs. Here are some of the ways I've tinkered with recently. Recommendation: in most cases, use pipx. 🔧]]></summary></entry><entry><title type="html">Tailscale, Mullvad, and More</title><link href="https://serverascode.com/2024/11/23/tailscale-mulladvpn.html" rel="alternate" type="text/html" title="Tailscale, Mullvad, and More" /><published>2024-11-23T00:00:00-05:00</published><updated>2024-11-23T00:00:00-05:00</updated><id>https://serverascode.com/2024/11/23/tailscale-mulladvpn</id><content type="html" xml:base="https://serverascode.com/2024/11/23/tailscale-mulladvpn.html"><![CDATA[<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
    <img src="/img/magazine-cards/tailscale-mullvad-200w.png" alt="Tailscale Mullvad" style="max-width: 200px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);" />
    <p><em>tldr; Tailscale allows you to create your own private, secure networks, like the LANs of yesteryear, and now they can have "exit nodes" that are Mullvad VPN servers.</em></p>
</div>

<hr />

<p>I’ve been a Tailscale user for a while now, though my use waned as I struggled to deal with using a VPN as an exit node. For real, that was my problem. I really struggled with the exit nodes and VPNs. For a while I had a tailscale exit node, as simple Linux VM running in Digital Ocean, which is still an option because Tailscale can use any server as an exit node, but it was a pain to setup and manage and update…and, and, and…</p>

<p>Now Tailscale has a feature where you can use Mullvad VPN endpoints as exit nodes. This is got me right back into using Tailscale full time on all of my devices.</p>

<p>Check out the feature page here: <a href="https://tailscale.com/mullvad">https://tailscale.com/mullvad</a></p>

<blockquote>
  <p>NOTE: I have no affiliation with Tailscale or Mullvad. I’m a big fan of Tailscale because it is a CANADIAN 🇨🇦 company!</p>
</blockquote>

<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px; background-color: #f5f5f5; padding: 20px; border-radius: 5px;">
    <a href="https://serverascode.com/2025/01/31/tailscale-kubernetes-operator.html">
        <img src="/img/magazine-cards/tailscale-k8s-operator-200w.png" alt="Tailscale Mullvad" style="max-width: 200px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);" />
    </a>
    <p><em>Also check out my other post about using <a href="https://serverascode.com/2025/01/31/tailscale-kubernetes-operator.html">Tailscale with Kubernetes</a>.</em></p>
</div>

<h2 id="tailscale-">Tailscale 🌐</h2>

<p>As mentioned, Tailscale is a Canadian company that makes a VPN service that is very easy to use. But what is a VPN? Why have one at all? What are VPNs really good for? Do they work? There are still a lot of questions out there as to what a “virtual private network” really is. Is it just something we login to at work in most enterprises?</p>

<blockquote>
  <p>Tailscale makes creating software-defined networks easy: securely connecting users, services, and devices. - <a href="https://tailscale.com">https://tailscale.com</a></p>
</blockquote>

<p>Here’s the CEO talking about the VPN/Internet problem in the Tailscale blog:</p>

<blockquote>
  <p>We looked at a lot of options, and talked to a lot of people, and there was an underlying cause for all the problems. The Internet. Things used to be simple. Remember the LAN? But then we connected our LANs to the Internet, and there’s been more and more firewalls and attackers everywhere, and things have slowly been degrading ever since. - <a href="https://tailscale.com/blog/new-internet">https://tailscale.com/blog/new-internet</a></p>
</blockquote>

<p>I don’t want to get into the philosophical discussion here, but I think Tailscale is on to something, I’m just not exactly sure what it is…possibly something like how social networks may be changing into group chats. But that is for another blog post.</p>

<h2 id="mullvad-">Mullvad 🦊</h2>

<p>I have used PIA, Private Internet Access, for a long time. It’s a great VPN service. Mullvad is similar, but with a few key differences in that they are heavily privacy focused and have a unique way of “logging in”.</p>

<p>Prior to realizing that Tailscale could use Mullvad as an exit node, I had coincidentally been using Mullvad as my VPN for a month or so, wanting to try something new after my PIA subscription expired. It’s a bit more expensive, but the model is interesting in that you don’t have a subscription really, instead you pay $5 USD per month and you don’t have a username or password, only an account ID.</p>

<p>One thing to note is that Mullvad just doesn’t have the same wide Internet pipes as PIA does, though they do have servers in Canada. However, I don’t see that much of a difference in speed, though it is there. So that is something to consider if you are a heavy downloader.</p>

<p>Overall, a fascinating service that I need to learn more about.</p>

<h2 id="tailscale-and-mullvad-together-">Tailscale and Mullvad Together 🤝</h2>

<p>Basically you enable Mullvad in Tailscale, it costs $5 USD per month for up to 5 devices. This 5 devices model is really useful, because that’s about what I have in terms of the number of devices that should be on Tailscale. Phones. Workstations. Laptops. Entertainment devices. Servers. Five devices is a good number for me, but if you need more, you just pay more.</p>

<p>First, enable Mullvad in Tailscale. Go to “Settings” and you can find it there.</p>

<p><img src="/img/tailscale-mullvad1.png" alt="Tailscale Mullvad" /></p>

<p>After adding devices you should see something like the below.</p>

<blockquote>
  <p>NOTE: I’ve removed my devices from the list of course.</p>
</blockquote>

<p><img src="/img/tailscale-mullvad2.png" alt="Tailscale Mullvad" /></p>

<p>Once you enable Mullvad in Tailscale, you can select it as an exit node on your Tailscale devices. That’s it. No need to configure Tailscale, then configure Mullvad, then troubleshoot the inevitable configuration issues.</p>

<h2 id="using-mullvad-as-an-exit-node-">Using Mullvad as an Exit Node 🔄</h2>

<p>If you want to see all the exit nodes:</p>

<pre><code class="language-bash">$ tailscale exit-node list

 IP                  HOSTNAME                         COUNTRY            CITY                   STATUS       
 100.91.198.95       al-tia-wg-001.mullvad.ts.net     Albania            Tirana                 -            
 100.65.216.68       au-adl-wg-301.mullvad.ts.net     Australia          Any                    -            
 100.65.216.68       au-adl-wg-301.mullvad.ts.net     Australia          Adelaide               -            
 100.70.240.117      au-bne-wg-301.mullvad.ts.net     Australia          Brisbane               -            
 100.117.126.96      au-mel-wg-301.mullvad.ts.net     Australia          Melbourne              -            
 100.88.22.25        au-per-wg-301.mullvad.ts.net     Australia          Perth                  -            
 100.100.169.122     au-syd-wg-001.mullvad.ts.net     Australia          Sydney                 -            
 100.79.65.118       at-vie-wg-001.mullvad.ts.net     Austria            Vienna                 -            
 100.120.7.76        be-bru-wg-101.mullvad.ts.net     Belgium            Brussels               -            
SNIP!
</code></pre>

<p>I use the <code>just</code> command runner to setup some easy commands to enable/disable Mullvad as an exit node.</p>

<pre><code class="language-bash">tailscale-use-vpn:
	sudo tailscale set \
		--exit-node-allow-lan-access \
		--exit-node=${MULLVAD_EXIT_NODE}

tailscale-no-vpn:
	# blank exit node
	sudo tailscale set --exit-node=
</code></pre>

<p>So if I need to I can turn off the VPN, for example Reddit blocks VPNs, not that I use Reddit, but it certainly comes up in Google searches.</p>

<h2 id="tailscale-access-control-list-">Tailscale Access Control List 🔒</h2>

<p>While Tailscale does talk about being easy to use, it also has complex looking <a href="https://tailscale.com/kb/1018/acls">ACLs</a>. I hadn’t used the ACLs previously, but now with more devices on Tailscale, I wanted to control what could access what, specifically I wanted a couple of devices only to be able to use the exit nodes, not access any other devices on the tailnet.</p>

<p>I struggled a bit with the ACLs, as any kind of RBAC is challenging to get right, but I had three main realizations that allowed me to get the right setup.</p>

<p>1. The only action is “accept”…this rattled my cage for a bit, as I was expecting deny or some other keywords.</p>

<blockquote>
  <p>Tailscale access rules deny access by default. As a result, the only possible action is accept. accept allows traffic from the source (src) to the destination (dst). - <a href="https://tailscale.com/kb/1337/acl-syntax">docs</a></p>
</blockquote>

<p>2. Users: You can control based on what user the device is logged in as on the tailnet. I didn’t realize this initially and was just trying to configure by device. And then realizing my mistake, it was much easier, as my main devices are logged in as me, and the other Internet/VPN only devices have their own users that were invited to the tailnet. Duh!</p>

<p>3. Groups: There is an “autogroup” for accessing the Internet which means you can set users to only have access to the Internet, and not any other devices on the tailnet. Perfect!</p>

<p><img src="/img/tailscale-mullvad3.png" alt="Tailscale ACLs" /></p>

<p>In the end my ACLs were maybe 10 lines of text, but it took a while to get there.</p>

<h2 id="conclusion-">Conclusion 🎯</h2>

<p>I’m really happy to be back to using Tailscale full time. We all really need to have better operational security for our Internet, phones, and application use…which I may be violating by even mentioning my use of Tailscale and Mullvad. But I think it’s a good thing to be talking about, and I hope to see more people using better tools to secure their Internet access.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[tldr; Tailscale allows you to create your own private, secure networks, like the LANs of yesteryear, and now they can have "exit nodes" that are Mullvad VPN servers.]]></summary></entry><entry><title type="html">falcoctl: Installation and Management of Falco Artifacts</title><link href="https://serverascode.com/2024/11/01/falcoctl.html" rel="alternate" type="text/html" title="falcoctl: Installation and Management of Falco Artifacts" /><published>2024-11-01T00:00:00-04:00</published><updated>2024-11-01T00:00:00-04:00</updated><id>https://serverascode.com/2024/11/01/falcoctl</id><content type="html" xml:base="https://serverascode.com/2024/11/01/falcoctl.html"><![CDATA[<div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
    <img src="/img/magazine-cards/falcoctl-200w.png" alt="falcoctl" style="max-width: 200px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);" />
    <p><em>tl;dr: <a href="https://github.com/falcosecurity/falcoctl">falcoctl</a> is an attempt to make it easier to distribute and upgrade Falco artifacts, such as rules and plugins.</em></p>
</div>

<hr />

<h2 id="what-is-falco">What is Falco?</h2>

<blockquote>
  <p>Falco is a cloud native security tool that provides runtime security across hosts, containers, Kubernetes, and cloud environments. It leverages custom rules on Linux kernel events and other data sources through plugins, enriching event data with contextual metadata to deliver real-time alerts. Falco enables the detection of abnormal behavior, potential security threats, and compliance violations. - <a href="https://falco.org/">Falco</a></p>
</blockquote>

<p><a href="https://falco.org/">Falco</a> is like a security camera for your servers, your Kubernetes nodes, and your cloud environments. It’s a way to detect and respond to security threats in real time.</p>

<p>The underlying technology relies on rules, which are really a set of configuration files. The point of these security rules is that the world around us is changing, and so we need new and updated rules to help us detect and respond to new and emerging threats. If you simply deploy the standard open source Falco rules and never change them, or do not add your own custom rules based on your own unique needs, you’re missing out on much of the power of Falco.</p>

<p>Once you have the base Falco technology, which is of course completely invaluable, the real work is in creating and managing the threat detection rules and then responding to alerts.</p>

<h2 id="distributed-systems">Distributed Systems</h2>

<p>It’s important to note that Falco deployments are like a single security camera. They are not, by default, a distributed collection of security cameras that all send their information to a central location, nor do they by default get their configuration from a central location.</p>

<p>This presents a challenge in that organizations often run many hundreds, thousands, or even tens of thousands of nodes, each with their own Falco installation. Additionally, Falco can also have plugins installed on each node, which further complicates the distribution of configuration.</p>

<ul>
  <li><strong>Configuration files</strong> - As mentioned, Falco is a rules based engine–so it needs the rules to work, and thus we have to manage those rules, and distribute them to potentially tens of thousands of nodes.</li>
</ul>

<p>How do we distribute these rules?</p>

<ul>
  <li><strong>Plugins</strong> - Over the last couple of years Falco has added a plugin framework which allows you in many ways to vastly increase the capacity of what Falco can monitor, i.e. historically Falco has looked at system calls, events from the Linux kernel, but with plugins you can add in other data sources, such as audit logs.</li>
</ul>

<p>So we have rules <em>and</em> plugins to manage, but how?</p>

<p>That is where falcoctl comes in.</p>

<h2 id="what-is-falcoctl">What is falcoctl?</h2>

<p>Here’s a good <a href="https://falco.org/blog/falcoctl-install-manage-rules-plugins/">blog post</a> from the Falco team that explains it well:</p>

<blockquote>
  <p>Since the launch of the plugin framework in January 2022, our adopters have requested an out-of-the-box solution to manage the lifecycle of rules (installation, updates). We heard your request and also created a guide to help you smoothly install the plugins. The Falco maintainers proposed the following solution to help with these issues: falcoctl. Falcoctl is a CLI tool that performs several useful tasks for Falco.</p>
</blockquote>

<p>falcoctl effectively manages artifacts for Falco, including rules, plugins, and configuration.</p>

<ul>
  <li>Install the falcoctl binary CLI application</li>
</ul>

<pre><code>LATEST=$(curl -sI https://github.com/falcosecurity/falcoctl/releases/latest | awk '/location: /{gsub("\r","",$2);split($2,v,"/");print substr(v[8],2)}')
curl --fail -LS "https://github.com/falcosecurity/falcoctl/releases/download/v${LATEST}/falcoctl_${LATEST}_linux_amd64.tar.gz" | tar -xz
sudo install -o root -g root -m 0755 falcoctl /usr/local/bin/falcoctl
</code></pre>

<ul>
  <li>Run it</li>
</ul>

<pre><code>root@falco:~# which falcoctl
/usr/local/bin/falcoctl
root@falco:~# falcoctl

     __       _                _   _ 
    / _| __ _| | ___ ___   ___| |_| |
   | |_ / _  | |/ __/ _ \ / __| __| |
   |  _| (_| | | (_| (_) | (__| |_| |
   |_|  \__,_|_|\___\___/ \___|\__|_|
									 
	
The official CLI tool for working with Falco and its ecosystem components

Usage:
  falcoctl [command]

Available Commands:
  artifact    Interact with Falco artifacts
  completion  Generate the autocompletion script for the specified shell
  driver      Interact with falcosecurity driver
  help        Help about any command
  index       Interact with index
  registry    Interact with OCI registries
  tls         Generate and install TLS material for Falco
  version     Print the falcoctl version information

Flags:
      --config string       config file to be used for falcoctl (default "/etc/falcoctl/falcoctl.yaml")
  -h, --help                help for falcoctl
      --log-format string   Set formatting for logs (color, text, json) (default "color")
      --log-level string    Set level for logs (info, warn, debug, trace) (default "info")

Use "falcoctl [command] --help" for more information about a command.
root@falco:~# 
</code></pre>

<h2 id="manage-falco-artifacts-with-falcoctl">Manage Falco Artifacts with falcoctl</h2>

<p>What we want to do is use falcoctl to manage our Falco artifacts. There are several components and features of falcoctl that we can use to do this.</p>

<ul>
  <li>Add an “index”</li>
</ul>

<pre><code>root@falco:~# sudo falcoctl index add falcosecurity https://falcosecurity.github.io/falcoctl/index.yaml
2024-11-01 19:30:11 INFO  Adding index
                      ├ name: falcosecurity
                      └ path: https://falcosecurity.github.io/falcoctl/index.yaml
2024-11-01 19:30:11 INFO  Index successfully added 
</code></pre>

<ul>
  <li>Review the config</li>
</ul>

<pre><code>root@falco:~# cat /etc/falcoctl/falcoctl.yaml 
artifact:
    follow:
        every: 6h0m0s
        falcoversions: http://localhost:8765/versions
        refs:
            - falco-rules:3
driver:
    hostroot: /
    name: falco
    repos:
        - https://download.falco.org/driver
    type:
        - modern_ebpf
    version: 7.3.0+driver
indexes:
    - name: falcosecurity
      url: https://falcosecurity.github.io/falcoctl/index.yaml
      backend: ""
</code></pre>

<ul>
  <li>Search for Falco artifacts</li>
</ul>

<pre><code>root@falco:~# falcoctl artifact search falco
INDEX        	ARTIFACT              	TYPE     	REGISTRY	REPOSITORY
falcosecurity	falco-incubating-rules	rulesfile	ghcr.io 	falcosecurity/rules/falco-incubating-rules
falcosecurity	falco-rules           	rulesfile	ghcr.io 	falcosecurity/rules/falco-rules
falcosecurity	falco-sandbox-rules   	rulesfile	ghcr.io 	falcosecurity/rules/falco-sandbox-rules
</code></pre>

<ul>
  <li>Search for Kubernetes artifacts</li>
</ul>

<pre><code>root@falco:~# falcoctl artifact search kubernetes
INDEX        	ARTIFACT          	TYPE     	REGISTRY	REPOSITORY
falcosecurity	k8saudit-eks      	plugin   	ghcr.io 	falcosecurity/plugins/plugin/k8saudit-eks
falcosecurity	k8saudit-gke      	plugin   	ghcr.io 	falcosecurity/plugins/plugin/k8saudit-gke
falcosecurity	k8saudit-gke-rules	rulesfile	ghcr.io 	falcosecurity/plugins/ruleset/k8saudit-gke
falcosecurity	k8saudit-rules    	rulesfile	ghcr.io 	falcosecurity/plugins/ruleset/k8saudit
falcosecurity	k8smeta           	plugin   	ghcr.io 	falcosecurity/plugins/plugin/k8smeta
falcosecurity	k8saudit          	plugin   	ghcr.io 	falcosecurity/plugins/plugin/k8saudit
</code></pre>

<ul>
  <li>Install the <code>falco-rules</code> artifact</li>
</ul>

<pre><code>root@falco:~# falcoctl artifact install falco-rules
2024-11-01 19:33:05 INFO  Resolving dependencies ... 
2024-11-01 19:33:05 INFO  Installing artifacts
                      └ refs: [ghcr.io/falcosecurity/rules/falco-rules:latest]
2024-11-01 19:33:05 INFO  Preparing to pull artifact
                      └ ref: ghcr.io/falcosecurity/rules/falco-rules:latest
2024-11-01 19:33:06 INFO  Pulling layer 8da145602705 
2024-11-01 19:33:06 INFO  Pulling layer b3990bf0209c                                            
2024-11-01 19:33:06 INFO  Pulling layer de2cd036fd7f                                            
2024-11-01 19:33:06 INFO  Verifying signature for artifact                                      
                      └ digest: ghcr.io/falcosecurity/rules/falco-rules@sha256:de2cd036fd7f9bb87de5d62b36d0f35ff4fa8afbeb9a41aa9624e5f6f9a004e1
2024-11-01 19:33:07 INFO  Signature successfully verified! 
2024-11-01 19:33:07 INFO  Extracting and installing artifact
                      ├ type: rulesfile
                      └ file: falco_rules.yaml.tar.gz
2024-11-01 19:33:07 INFO  Artifact successfully installed                                       
                      ├ name: ghcr.io/falcosecurity/rules/falco-rules:latest
                      ├ type: rulesfile
                      ├ digest: sha256:de2cd036fd7f9bb87de5d62b36d0f35ff4fa8afbeb9a41aa9624e5f6f9a004e1
                      └ directory: /etc/falco
</code></pre>

<h2 id="following-as-a-daemon">Following as a Daemon</h2>

<blockquote>
  <p>A great feature of falcoctl is its ability to run as a daemon to periodically check the artifacts’ repositories and automatically install new versions. - <a href="https://github.com/falcosecurity/falcoctl">falcoctl</a></p>
</blockquote>

<p>So this would be the key feature of falcoctl, because, again, it’s great to have the technology, but what does it do to make our lives easier?</p>

<p>When falcoctl tracks (follows) an artifact, it will automatically install new versions of that artifact without any human intervention, which I think is a good thing. Of course, we want to make sure that what we deploy works as expected, but that is a whole other can of worms.</p>

<p>So, with all that in mind, let’s create a service to run falcoctl as a daemon.</p>

<ul>
  <li>Create a service</li>
</ul>

<pre><code>cat &lt;&lt; 'EOF' | sudo tee /etc/systemd/system/falcoctl.service
[Unit]
Description=Falcoctl
After=network.target
StartLimitIntervalSec=0

[Service]
Type=simple
Restart=always
RestartSec=1
ExecStart=/usr/local/bin/falcoctl artifact follow
EOF
systemctl enable falcoctl
systemctl start falcoctl
</code></pre>

<ul>
  <li>Check the status now that it is running</li>
</ul>

<pre><code>root@falco:/etc/falcoctl# systemctl status falcoctl
● falcoctl.service - Falcoctl
     Loaded: loaded (/etc/systemd/system/falcoctl.service; static)
     Active: active (running) since Fri 2024-11-01 19:37:32 UTC; 11s ago
   Main PID: 5544 (falcoctl)
      Tasks: 7 (limit: 2296)
     Memory: 25.4M (peak: 25.6M)
        CPU: 674ms
     CGroup: /system.slice/falcoctl.service
             └─5544 /usr/local/bin/falcoctl artifact follow

Nov 01 19:37:33 falco falcoctl[5544]:                       └ artifact: ghcr.io/falcosecuri&gt;
Nov 01 19:37:33 falco falcoctl[5544]: 2024-11-01 19:37:33 INFO  Found new artifact version
Nov 01 19:37:33 falco falcoctl[5544]:                       ├ followerName: ghcr.io/falcosecuri&gt;
Nov 01 19:37:33 falco falcoctl[5544]:                       └ tag: 3
Nov 01 19:37:35 falco falcoctl[5544]: 2024-11-01 19:37:35 INFO  Artifact correctly installed
Nov 01 19:37:35 falco falcoctl[5544]:                       ├ followerName: ghcr.io/falcosecuri&gt;
Nov 01 19:37:35 falco falcoctl[5544]:                       ├ artifactName: ghcr.io/falcosecuri&gt;
Nov 01 19:37:35 falco falcoctl[5544]:                       ├ type: rulesfile
Nov 01 19:37:35 falco falcoctl[5544]:                       ├ digest: sha256:de2cd036fd7f9bb87d&gt;
Nov 01 19:37:35 falco falcoctl[5544]:                       └ directory: /etc/falco
root@falco:/etc/falcoctl# systemctl status falcoctl --no-pager
● falcoctl.service - Falcoctl
     Loaded: loaded (/etc/systemd/system/falcoctl.service; static)
     Active: active (running) since Fri 2024-11-01 19:37:32 UTC; 15s ago
   Main PID: 5544 (falcoctl)
      Tasks: 7 (limit: 2296)
     Memory: 25.4M (peak: 25.6M)
        CPU: 674ms
     CGroup: /system.slice/falcoctl.service
             └─5544 /usr/local/bin/falcoctl artifact follow

Nov 01 19:37:33 falco falcoctl[5544]:                       └ artifact: ghcr.io/falcosecu…ules:3
Nov 01 19:37:33 falco falcoctl[5544]: 2024-11-01 19:37:33 INFO  Found new artifact version
Nov 01 19:37:33 falco falcoctl[5544]:                       ├ followerName: ghcr.io/falco…ules:3
Nov 01 19:37:33 falco falcoctl[5544]:                       └ tag: 3
Nov 01 19:37:35 falco falcoctl[5544]: 2024-11-01 19:37:35 INFO  Artifact correctly installed
Nov 01 19:37:35 falco falcoctl[5544]:                       ├ followerName: ghcr.io/falco…ules:3
Nov 01 19:37:35 falco falcoctl[5544]:                       ├ artifactName: ghcr.io/falco…ules:3
Nov 01 19:37:35 falco falcoctl[5544]:                       ├ type: rulesfile
Nov 01 19:37:35 falco falcoctl[5544]:                       ├ digest: sha256:de2cd036fd7f…a004e1
Nov 01 19:37:35 falco falcoctl[5544]:                       └ directory: /etc/falco
Hint: Some lines were ellipsized, use -l to show in full.
</code></pre>

<p>Looks good.</p>

<h2 id="build-your-own-falcoctl-artifact">Build Your Own Falcoctl Artifact</h2>

<p>Let’s push a rules file into an OCI registry.</p>

<ul>
  <li>First create a rules file</li>
</ul>

<pre><code>cat &lt;&lt; 'EOF' | sudo tee ./custom_rules.yaml
- list: falco_binaries
  items: [falcoctl]
EOF
</code></pre>

<ul>
  <li>Login to the registry</li>
</ul>

<pre><code>root@falco:/etc/falcoctl# falcoctl registry auth basic some_registry -u 'your_user' -p 'some_password'
2024-11-01 19:52:43 INFO  Login succeeded registry: some_registry user: your_user
</code></pre>

<ul>
  <li>Now push that single rules file to the registry</li>
</ul>

<blockquote>
  <p>NOTE: We often think of “container images” as the only thing we can push to an OCI registry, but we can actually push any OCI-compliant artifact to an OCI registry, and over time we will see much more use of this.</p>
</blockquote>

<pre><code>export OCI_ARTIFACT_VERSION=latest
export OCI_REGISTRY=some_registry
export OCI_REPOSITORY=some_repo/falco-rules
export RULESET_FILE=custom_rules.yaml
falcoctl registry push \
    --config /dev/null \
    --type rulesfile \
    --version ${OCI_ARTIFACT_VERSION} \
    ${OCI_REGISTRY}/${OCI_REPOSITORY}:${OCI_ARTIFACT_VERSION} \
    ${RULESET_FILE}
</code></pre>

<ul>
  <li>Resulting output</li>
</ul>

<pre><code>root@falco:/etc/falcoctl# export OCI_ARTIFACT_VERSION=latest
export OCI_REGISTRY=some_registry
export OCI_REPOSITORY=some_repo/falco-rules
export RULESET_FILE=custom_rules.yaml
falcoctl registry push \
    --config /dev/null \
    --type rulesfile \
    --version ${OCI_ARTIFACT_VERSION} \
    ${OCI_REGISTRY}/${OCI_REPOSITORY}:${OCI_ARTIFACT_VERSION} \
    ${RULESET_FILE}
2024-11-01 20:15:19 INFO  Preparing to push artifact
                      ├ name: some_registry/some_repo/falco-rules:latest
                      └ type: rulesfile
2024-11-01 20:15:19 ERROR open custom_rules.yaml: no such file or directory 
root@falco:/etc/falcoctl# cd 
root@falco:~# falcoctl registry push     --config /dev/null     --type rulesfile     --version ${OCI_ARTIFACT_VERSION}     ${OCI_REGISTRY}/${OCI_REPOSITORY}:${OCI_ARTIFACT_VERSION}     ${RULESET_FILE}
2024-11-01 20:15:24 INFO  Preparing to push artifact
                      ├ name: some_registry/some_repo/falco-rules:latest
                      └ type: rulesfile
2024-11-01 20:15:24 INFO  Parsing dependencies from:  rulesfile: custom_rules.yaml
2024-11-01 20:15:24 WARN  No dependencies were provided by the user and none were found in the
                      │   rulesfile.
2024-11-01 20:15:24 INFO  Parsing requirements from:  rulesfile: custom_rules.yaml
2024-11-01 20:15:24 WARN  No requirements were provided by the user and none were found in the
                      │   rulesfile.
2024-11-01 20:15:24 INFO  Pushing layer d5c35695420a 
2024-11-01 20:15:26 INFO  97c38f4c17c8: layer already exists                                    
2024-11-01 20:15:26 INFO  Pushing layer c891d7815e0a 
2024-11-01 20:15:26 INFO  Artifact pushed                                                       
                      ├ name: some_registry/some_repo/falco-rules:latest
                      ├ type: rulesfile
                      └ digest: sha256:c891d7815e0a30a1a73e026aea4603503b0a12df9bc8b7efc38f61de2d77bd6b
</code></pre>

<ul>
  <li>Now follow the artifact by updating the falcoctl.yaml file</li>
</ul>

<blockquote>
  <p>NOTE: Below I added <code>some_registry/some_repo/falco-rules:latest</code> to the <code>refs</code> section.</p>
</blockquote>

<pre><code>root@falco:/etc/falcoctl# cat falcoctl.yaml
artifact:
    follow:
        every: 6h0m0s
        falcoversions: http://localhost:8765/versions
        refs:
            - falco-rules:3
            - some_registry/some_repo/falco-rules:latest
driver:
    hostroot: /
    name: falco
    repos:
        - https://download.falco.org/driver
    type:
        - modern_ebpf
    version: 7.3.0+driver
indexes:
    - name: falcosecurity
      url: https://falcosecurity.github.io/falcoctl/index.yaml
      backend: ""
</code></pre>

<ul>
  <li>Restart the falcoctl service</li>
</ul>

<pre><code>systemctl restart falcoctl
</code></pre>

<ul>
  <li>Check the status of the falcoctl service</li>
</ul>

<pre><code>systemctl status falcoctl
</code></pre>

<ul>
  <li>And check if the new rules file was installed</li>
</ul>

<pre><code>root@falco:~# cat /etc/falco/custom_rules.yaml 
- list: falco_binaries
  items: [falcoctl]
</code></pre>

<p>It was!</p>

<ul>
  <li>There are falcoctl logs as well</li>
</ul>

<pre><code>root@falco:~# grep some_repo /var/log/syslog
2024-11-01T20:16:57.198277+00:00 falco falcoctl[5819]:                       ├ artifact: some_registry/some_repo/falco-rules:latest
2024-11-01T20:16:57.200084+00:00 falco falcoctl[5819]:                       └ artifact: some_registry/some_repo/falco-rules:latest
2024-11-01T20:16:57.433872+00:00 falco falcoctl[5819]:                       ├ followerName: some_registry/some_repo/falco-rules:latest
2024-11-01T20:16:59.154603+00:00 falco falcoctl[5819]:                       ├ followerName: some_registry/some_repo/falco-rules:latest
2024-11-01T20:16:59.154713+00:00 falco falcoctl[5819]:                       ├ artifactName: some_registry/some_repo/falco-rules:latest
</code></pre>

<p>Easy peasy. Well, at least getting it started. Now you need to automate the creation of the artifact, and of course write your own rules, which is the hard part once you have the technology.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In theory, you could deploy falcoctl as a daemon to every host you have, and configure it to check for your new rules basically on a cronjob-like schedule. Need every host to have a new rules file? No problem, just push the new rules file to the OCI registry and the falcoctl daemon will pull it down and install it.</p>

<p>Will that scale? I don’t know. Maybe…maybe not.</p>

<p>However, even once you have Falco installed, and then use falcoctl to have a distribution mechanism in place, you still need to customize your rules. Technology only gets us so far.</p>

<h2 id="ps-sysdig">PS. Sysdig</h2>

<p>I work at <a href="https://sysdig.com">Sysdig</a>, and while we use and support Falco, we’ve also built our enterprise product to have a much wider use case (see <a href="https://www.sysdig.com/cnapp">CNAPP</a> which includes CSPM, CIEM, vulnerability management, and more), and to be considerably more scalable than vanilla open source Falco. Sysdig does all the heavy lifting, rule distribution, etc., etc. And most importantly, in the context of threat detection, we write the rules for you as well.</p>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><a href="https://falco.org/blog/gitops-your-falco-rules/">Gitops Your Falco Rules</a></li>
  <li><a href="https://github.com/falcosecurity/falcoctl">falcoctl</a></li>
  <li><a href="https://falco.org/docs/getting-started/falco-linux-quickstart/">Try Falcoctl</a></li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[tl;dr: falcoctl is an attempt to make it easier to distribute and upgrade Falco artifacts, such as rules and plugins.]]></summary></entry><entry><title type="html">The Numerous Pains of Programming: Death by a Thousand Cuts</title><link href="https://serverascode.com/2024/10/25/pain-of-programming.html" rel="alternate" type="text/html" title="The Numerous Pains of Programming: Death by a Thousand Cuts" /><published>2024-10-25T00:00:00-04:00</published><updated>2024-10-25T00:00:00-04:00</updated><id>https://serverascode.com/2024/10/25/pain-of-programming</id><content type="html" xml:base="https://serverascode.com/2024/10/25/pain-of-programming.html"><![CDATA[<p><img src="/img/posts/deathcuts.png" alt="/img/posts/deathcuts.png" /></p>

<p>I recently started building a small Python application, less than 1000 lines of code. However, it’s been a real challenge to get it to the point where it can be deployed and run in a production environment. I’ve done this before, but it’s always difficult, and each time I’m reminded of how much effort it takes, in part because I always have to start anew.</p>

<p>As a part-time developer…which of these extra things do I actually have to do? And to what extent? The code, sure, but all the other stuff?</p>

<h2 id="the-pain-of-programming">The Pain of Programming</h2>

<p>For most applications, writing the code is relatively straightforward, though it can still be challenging. However, there are tons of other things around the code, all the extra work you have to do to make it a quote unquote “real application”.</p>

<p>I’m not even including things like choosing a language or framework.</p>

<blockquote>
  <p>NOTE: This is not a perfect, comprehensive list–it’s a brainstorm of things I can think of that I’ve had to do, or might have to do to make an application “real” and somewhat professional.</p>
</blockquote>

<ol>
  <li>Writing and maintaining comprehensive test suites, unit tests, integration tests, etc.</li>
  <li>Setting up testing infrastructure and testing frameworks</li>
  <li>Designing and implementing CI/CD pipelines</li>
  <li>Creating and maintaining distributable packages</li>
  <li>Managing production environment deployment and monitoring</li>
  <li>Implementing release management</li>
  <li>Writing and maintaining documentation</li>
  <li>Creating and updating system architecture diagrams</li>
  <li>Managing version control workflows and git complexity</li>
  <li>Supporting and responding to user needs and feedback</li>
  <li>Implementing basic security best practices</li>
  <li>Conducting stress testing and performance optimization</li>
  <li>Containerizing the application and creating Kubernetes manifests</li>
  <li>Setting up vulnerability scanning</li>
  <li>Managing security issues in dependencies</li>
  <li>Managing databases, data models, and migrations</li>
  <li>Configuring IDE settings and extensions</li>
  <li>Setting up development environments (e.g., virtual environments)</li>
  <li>Managing dependency trees and version conflicts</li>
  <li>Configuring and maintaining linters and formatters</li>
  <li>Setting up logging and monitoring infrastructure</li>
  <li>What kind of logging…structured, unstructured, etc.</li>
  <li>Dealing with debugging tools…more than print statements?</li>
  <li>Testing with SSL certificates</li>
  <li>Deploying on different operating systems and user environments</li>
  <li>Dealing with authentication, perhaps RBAC too</li>
  <li>Do I need different environments for development, testing, staging, and production?</li>
  <li>Keeping track of issues, tickets, and other project management tasks</li>
  <li>How to get secrets and configuration into the application safely and securely</li>
  <li>Dealing with updating the software, from configuration to removing features and functionality</li>
  <li>Understanding resource requirements, memory, cpu, etc. and what to set limits to in production</li>
  <li>Threat modelling–how would an attacker get in, what would be the impact, etc.</li>
  <li>What license should I use for the software? What does it mean if I choose the wrong one?</li>
  <li>What metrics should it output, and how?</li>
  <li>Configuring…the config file. What should it look like? How to validate it? What’s a good layout?</li>
  <li>Finding dead and unused code</li>
  <li>Removing debug statements in production</li>
</ol>

<p>I could go on, and I’m sure there are many more.</p>

<p>All of the above is an enormous amount of work, work that goes far beyond the few hundred or thousand lines of code you write for the core of a simple application. For a small application, it doesn’t seem worth it. There doesn’t seem to be much in the way of easy-to-use automation or other tools to help with all this–it’s just a big old mess of tasks that add up to a lot of work.</p>

<h2 id="table-formatted-pain">Table Formatted Pain</h2>

<p>Here’s a table view of the list above.</p>

<p>Again, this is not a comprehensive list, but a brainstorm of things I can think of that I’ve had to do, or might have to do, to make an application “real” and somewhat professional. I’m sure there are better lists out there somewhere…</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Tasks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Testing &amp; Quality</strong></td>
      <td>• Writing and maintaining test suites (unit, integration)<br />• Setting up testing infrastructure and frameworks<br />• Conducting stress testing and performance optimization<br />• Testing with SSL certificates<br />• Detecting dead and unused code</td>
    </tr>
    <tr>
      <td><strong>Infrastructure &amp; Deployment</strong></td>
      <td>• Designing and implementing CI/CD pipelines<br />• Managing production environment deployment and monitoring<br />• Managing different environments (dev, test, staging, prod)<br />• Containerizing applications and Kubernetes manifests<br />• Deploying on different operating systems/environments</td>
    </tr>
    <tr>
      <td><strong>Security</strong></td>
      <td>• Implementing basic security best practices<br />• Setting up vulnerability scanning<br />• Managing security issues in dependencies<br />• Dealing with authentication and RBAC<br />• Threat modeling<br />• Managing secrets and configuration securely</td>
    </tr>
    <tr>
      <td><strong>Development Environment</strong></td>
      <td>• Configuring IDE settings and extensions<br />• Setting up development environments<br />• Managing dependency trees and conflicts<br />• Configuring and maintaining linters/formatters<br />• Managing version control workflows</td>
    </tr>
    <tr>
      <td><strong>Documentation &amp; Architecture</strong></td>
      <td>• Writing and maintaining documentation<br />• Creating/updating system architecture diagrams<br />• Managing licenses and compliance<br />• Maintaining configuration file structure and validation</td>
    </tr>
    <tr>
      <td><strong>Operations &amp; Monitoring</strong></td>
      <td>• Setting up logging infrastructure (structured/unstructured)<br />• Managing debugging tools<br />• Understanding resource requirements (CPU, memory)<br />• Output metrics configuration and management<br />• Removing debug statements in production</td>
    </tr>
    <tr>
      <td><strong>Data Management</strong></td>
      <td>• Managing databases, data models, and migrations</td>
    </tr>
    <tr>
      <td><strong>Distribution and Upgrades</strong></td>
      <td>• Creating and maintaining distributable packages<br />• Managing software updates and feature deprecation</td>
    </tr>
    <tr>
      <td><strong>Project Management</strong></td>
      <td>• Supporting and responding to user needs/feedback<br />• Keeping track of issues, tickets, and tasks<br />• Implementing release management</td>
    </tr>
  </tbody>
</table>

<h2 id="what-is-a-real-application">What is a real application?</h2>

<p>I keep using the term “real application”, but what does it mean? What makes an application real? I suppose what I mean is an enterprise, production-grade application of some kind. But that doesn’t mean much–I’m not sure anyone knows what makes an application production-grade. It’s kind of a vague term, and I think we could probably do better. The reality is that programming is more of an art, a dedicated craft, with hundreds of things that need to be done and hundreds of other tools, technologies, and techniques that can be used to do them. Some of this is optional, some of it is required, and some of it is just good practice. It’s not always clear which is which.</p>

<h2 id="tedious-work">Tedious work</h2>

<p>This list is a decomposition of what a developer has to do. I find all this extra work absolutely exhausting and, frankly, quite tedious. For every single one of these steps, it seems to me that there must be a better way. And for some of them, I’m sure there is, maybe I just don’t know about it yet. But I don’t think there’s a single tool, technique, or technology that can help with all of them.</p>

<p>Ultimately, I would love to have a magic wand that I could wave that would do all of that, so I could just focus on the code that delivers the value, but I don’t think that’s possible. Generative AI isn’t going to help that much, you can imagine it tying it all together somehow, but the problems are still there, they’re just hidden, like a river of lava under the surface.</p>

<p>Imagine what we could do if we just got rid of all that boredom?</p>

<h2 id="an-application-can-never-be-done-but-it-must-be-run">An application can never be done, but it must be run.</h2>

<p>I think the reality is that an application can never be finished. There is always more work to be done. It can never be 100% finished - there is always something missing, which is an incredible place to be when you consider that one of the main outputs of humanity at this point in time, one of our main economic drivers, is the writing and running of software. What a bizarre situation.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Incus Installation and Use - Setup Storage Pools and Bridged Networking</title><link href="https://serverascode.com/2024/10/19/incus-installation-and-use.html" rel="alternate" type="text/html" title="Incus Installation and Use - Setup Storage Pools and Bridged Networking" /><published>2024-10-19T00:00:00-04:00</published><updated>2024-10-19T00:00:00-04:00</updated><id>https://serverascode.com/2024/10/19/incus-installation-and-use</id><content type="html" xml:base="https://serverascode.com/2024/10/19/incus-installation-and-use.html"><![CDATA[<p>In this post I’ll show you how to install and setup <a href="https://linuxcontainers.org/incus/docs/main/">Incus</a> on a physical host running Ubuntu 24.04. I’ll setup a storage pool and a bridge network, then launch a VM. Once this is all done, I’ll have a nice homelab server that can spin up many virtual machines and do it quickly, putting them on the right storage pool, on a separate network.</p>

<h2 id="what-is-incus">What is Incus?</h2>

<blockquote>
  <p>Incus is a next-generation system container, application container, and virtual machine manager. It provides a user experience similar to that of a public cloud. With it, you can easily mix and match both containers and virtual machines, sharing the same underlying storage and network. - <a href="https://linuxcontainers.org/incus/docs/main/">Incus Docs</a></p>
</blockquote>

<p>Basically, once you install Incus you can ask it for virtual machines or system containers (not Docker containers, but system conatiners) and it will go and build them for you.</p>

<h2 id="physical-host">Physical Host</h2>

<p>I’m using Ubuntu 24.04 on my homelab server.</p>

<pre><code>$ cat /etc/lsb-release 
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=24.04
DISTRIB_CODENAME=noble
DISTRIB_DESCRIPTION="Ubuntu 24.04.1 LTS"
</code></pre>

<p>It’s an older server, but it’s got a lot of memory.</p>

<pre><code>$ free -h
               total        used        free      shared  buff/cache   available
Mem:           188Gi       3.1Gi       185Gi       673Mi       2.5Gi       185Gi
Swap:          8.0Gi          0B       8.0Gi
</code></pre>

<p>And lots of room for disks and such, including a 2TB NVMe drive, which I’ll use for my main storage pool.</p>

<h2 id="install-incus">Install Incus</h2>

<p>I’ll be following the Incus docs - <a href="https://linuxcontainers.org/incus/docs/main/installing/#installing">https://linuxcontainers.org/incus/docs/main/installing/#installing</a></p>

<p>First, install the incus and qemu packages; need qemu for the VM support.</p>

<pre><code>apt install incus qemu-system
</code></pre>

<p>Incus is a small set of packages, qemu is a fair bit larger.</p>

<p>Add your user to the incus group.</p>

<pre><code>$ sudo adduser curtis incus-admin
info: Adding user `curtis' to group `incus-admin' ...
</code></pre>

<p>Log out and log back in to get the new group, or use newgrp, whatever you want.</p>

<pre><code>$ incus ls
+------+-------+------+------+------+-----------+
| NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS |
+------+-------+------+------+------+-----------+
</code></pre>

<h2 id="storage-pool">Storage Pool</h2>

<p>I have a NVMe drive mounted on /mnt/nvme0n1 and I want to use that to back my incus managed virtual machines.</p>

<pre><code>$ sudo mkdir -p /mnt/nvme0n1/incus
$ incus storage create p1 dir source=/mnt/nvme0n1/incus
Storage pool p1 created
$ incus storage ls
+------+--------+--------------------+-------------+---------+---------+
| NAME | DRIVER |       SOURCE       | DESCRIPTION | USED BY |  STATE  |
+------+--------+--------------------+-------------+---------+---------+
| p1   | dir    | /mnt/nvme0n1/incus |             | 0       | CREATED |
+------+--------+--------------------+-------------+---------+---------+
</code></pre>

<p>Some files and directories are created in /mnt/nvme0n1/incus.</p>

<pre><code>$ ls /mnt/nvme0n1/incus/
buckets     containers-snapshots  custom-snapshots  virtual-machines
containers  custom                images            virtual-machines-snapshots
</code></pre>

<p>Very slick and easy to create the storage pool.</p>

<p>Now to build a VM using that storage pool.</p>

<pre><code>$ incus launch images:ubuntu/24.04 test --vm --storage p1
Launching test
                                          
The instance you are starting doesn't have any network attached to it.
  To create a new network, use: incus network create
  To attach a network to an instance, use: incus network attach
</code></pre>

<p>Note that I don’t have a network configured, so this didn’t actually start the VM.</p>

<p>But, files are created for the VM in the storage pool.</p>

<pre><code class="language-bash">$ sudo tree /mnt/nvme0n1/incus/
/mnt/nvme0n1/incus/
├── buckets
├── containers
├── containers-snapshots
├── custom
├── custom-snapshots
├── images
├── virtual-machines
│   └── test
│       ├── agent-client.crt
│       ├── agent-client.key
│       ├── agent.crt
│       ├── agent.key
│       ├── backup.yaml
│       ├── config
│       │   ├── agent.conf
│       │   ├── agent.crt
│       │   ├── agent.key
│       │   ├── agent-mounts.json
│       │   ├── files
│       │   │   ├── hostname.tpl.out
│       │   │   ├── hosts.tpl.out
│       │   │   └── metadata.yaml
│       │   ├── incus-agent
│       │   ├── install.sh
│       │   ├── lxd-agent -&gt; incus-agent
│       │   ├── nics
│       │   ├── server.crt
│       │   ├── systemd
│       │   │   ├── incus-agent.service
│       │   │   └── incus-agent-setup
│       │   └── udev
│       │       └── 99-incus-agent.rules
│       ├── metadata.yaml
│       ├── OVMF_VARS_4M.ms.fd
│       ├── qemu.nvram -&gt; OVMF_VARS_4M.ms.fd
│       ├── root.img
│       └── templates
│           ├── hostname.tpl
│           └── hosts.tpl
└── virtual-machines-snapshots

16 directories, 25 files

</code></pre>

<h2 id="networking">Networking</h2>

<p>OK, I love networking, but it can also be a pain, especially when we’re dealing with bridges and virtual machines, etc, etc. I like to think of networking as moving packets as quickly as possible, not configuring bridges, but there’s just no avoiding it.</p>

<p>The physical host has the below netplan configuration, where I’ve added a VLAN to eth3.</p>

<pre><code>$ sudo cat 50-cloud-init.yaml 
network:
    ethernets:
        eno1: {}
        eth3: {}
    version: 2
    vlans:
        eno1.101:
            addresses:
            - 10.100.1.20/24
            id: 101
            link: eno1
            nameservers:
                addresses:
                - 10.100.1.3
                search: []
            routes:
            -   to: default
                via: 10.100.1.1
        eth3.105:
            id: 105
            link: eth3
        eth3.106:
            id: 106
            link: eth3
</code></pre>

<p>I’m going to tell incus to create a bridge on a network interface that has a VLAN tag on it, eth3.106.</p>

<pre><code>$ incus network create br106 \
  --type=bridge \
  bridge.external_interfaces=eth3.106 \
  ipv4.dhcp=false \
  ipv4.nat=false \
  ipv6.nat=false \
  ipv4.address=none \
  ipv6.address=none
</code></pre>

<p>That command creates this config:</p>

<pre><code>$ incus network show br106
config:
  bridge.external_interfaces: eth3.106
  ipv4.address: none
  ipv4.dhcp: "false"
  ipv4.nat: "false"
  ipv6.address: none
  ipv6.nat: "false"
description: ""
name: br106
type: bridge
used_by:
- /1.0/instances/test
managed: true
status: Created
locations:
- none
</code></pre>

<p>DHCP is actually provided by my physical switch, not incus. So when I launch a VM, it starts with DHCP, but that DHCP address is coming from the upstream switch, not incus. This is what I want.</p>

<p>I can launch a VM with this network on the previously configured storage pool.</p>

<pre><code>$ incus launch images:ubuntu/24.04 test --vm --storage p1 --network br106
</code></pre>

<p>And list the VMs to see the new one, note that we can see the IP address of the VM even though Incus isn’t doing the IP address management.</p>

<pre><code>$ incus ls
+------+---------+---------------------+------+-----------------+-----------+
| NAME |  STATE  |        IPV4         | IPV6 |      TYPE       | SNAPSHOTS |
+------+---------+---------------------+------+-----------------+-----------+
| test | RUNNING | 10.100.6.250 (enp5s0) |      | VIRTUAL-MACHINE | 0         |
+------+---------+---------------------+------+-----------------+-----------+
</code></pre>

<p>Hop onto that VM and ping 1.1.1.1:</p>

<pre><code>$ incus shell test
root@test:~# ping -c 3 1.1.1.1
PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data.
64 bytes from 1.1.1.1: icmp_seq=1 ttl=53 time=5.80 ms
64 bytes from 1.1.1.1: icmp_seq=2 ttl=53 time=3.43 ms
64 bytes from 1.1.1.1: icmp_seq=3 ttl=53 time=3.47 ms

--- 1.1.1.1 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 3.425/4.232/5.802/1.110 ms
</code></pre>

<p>Network is online!</p>

<p>For various reasons I use Mikrotik switches/routers in my homelab, so this interface might look different on your network. Obviously I don’t have a lot of DHCP going on. :)</p>

<pre><code>[admin@MikroTik] &gt; /ip dhcp-server lease print 
Flags: X - disabled, R - radius, D - dynamic, B - blocked 
 #   ADDRESS                                                                    MAC-ADDRESS       HOST-NAME                                 SERVER                                 RATE-LIMIT                                 STATUS 
 0 D 10.100.6.250                                                                 00:16:3E:4D:15:97 distrobuilder-705ecd65-121a-4b5b-8cdc-... dhcp1                                                                             bound  
[admin@MikroTik] &gt; 
</code></pre>

<p>And we can see the DHCP lease is for the VM.</p>

<h2 id="incus-profiles">Incus Profiles</h2>

<p>Finally, I’ll create a profile for the VM, or rather I’ll edit the default profile to use the bridge network and the storage pool.</p>

<pre><code class="language-bash">$ incus profile show default
config: {}
description: Default Incus profile
devices:
  eth0:
    network: br106
    type: nic
  root:
    path: /
    pool: p1
    type: disk
name: default
used_by:
- /1.0/instances/test
</code></pre>

<h2 id="conclusion">Conclusion</h2>

<p>And there you have it. Incus is now managing my virtual machines, putting them on my storage pool, and giving me a bridge network with IPs from my DHCP server.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[In this post I’ll show you how to install and setup Incus on a physical host running Ubuntu 24.04. I’ll setup a storage pool and a bridge network, then launch a VM. Once this is all done, I’ll have a nice homelab server that can spin up many virtual machines and do it quickly, putting them on the right storage pool, on a separate network.]]></summary></entry><entry><title type="html">Why Aren’t You Using Incus to Create Containers and Virtual Machines?</title><link href="https://serverascode.com/2024/10/12/incus.html" rel="alternate" type="text/html" title="Why Aren’t You Using Incus to Create Containers and Virtual Machines?" /><published>2024-10-12T00:00:00-04:00</published><updated>2024-10-12T00:00:00-04:00</updated><id>https://serverascode.com/2024/10/12/incus</id><content type="html" xml:base="https://serverascode.com/2024/10/12/incus.html"><![CDATA[<h1 id="incus">Incus</h1>

<p>Virtual machines remain the main building block of pretty much all infrastructure. We tend to forget about the technology and just how entrenched it is in our daily technical lives. Ok, that’s a pretty heavy statement for a blog post, but I do think we forget about virtual machines and just how valuable and secure the technology is–most public cloud services are loss leaders for the VM part of their business.</p>

<p>Anyways, what I want to talk about is <a href="https://linuxcontainers.org/incus/introduction/">Incus</a>, a way to easily create containers AND virtual machines.</p>

<blockquote>
  <p>NOTE: I use Incus to exclusively create virtual machines, and don’t use the container functionality that much. I would imagine that most people use the container functionality more. So while I’ll touch on the system container functionality, I use Incus for local VMs.</p>
</blockquote>

<h2 id="what-is-incus">What is Incus?</h2>

<blockquote>
  <p>When using Incus, you can manage your instances (containers and VMs) with a simple command line tool, directly through the REST API or by using third-party tools and integrations. Incus implements a single REST API for both local and remote access. The Incus project was created by Aleksa Sarai as a community driven alternative to Canonical’s LXD. Today, it’s led and maintained by many of the same people that once created LXD. - <a href="https://linuxcontainers.org/incus/introduction/">Incus Docs</a></p>
</blockquote>

<p>With Incus, you can easily create virtual machines and containers.</p>

<p>I don’t know all the history of the project, where it comes from in terms of LXD/LXC, etc, but I do know that I need a way to easily create virtual machines on my local computer, and that I really enjoy using Incus. So easy.</p>

<p>Example of creating a virtual machine:</p>

<pre><code class="language-bash">incus launch ubuntu:22.04 my-server --vm
</code></pre>

<p>It’s that easy. Especially on Ubuntu 24.04, where you can just install the <code>incus</code> package from the default repositories.</p>

<p>I also alias the incus command to this script because I always forget the incus command syntax, and I’m super lazy. So this would create a default sized VM with just <code>vm launch my-vm</code>.</p>

<pre><code class="language-bash">#!/bin/bash

launch_vm() {
  if [ -z "$1" ]; then
    echo "Usage: $0 launch &lt;vm-name&gt;"
    echo "Example: $0 launch my-ubuntu-vm"
    exit 1
  fi

  local name="$1"
  local cpu=2
  local memory="4GiB"
  local disk="40GiB"

  incus launch images:ubuntu/24.04 "$name" --vm \
    --device root,size="$disk" \
    -c limits.cpu="$cpu" \
    -c limits.memory="$memory"
}

list_vms() {
  incus ls
}

show_help() {
  echo "Usage: $0 &lt;command&gt; [options]"
  echo
  echo "Commands:"
  echo "  launch &lt;vm-name&gt;  Launch a new VM"
  echo "  ls                List all VMs"
  echo "  help              Show this help message"
  echo
  echo "For other commands, this script will pass them directly to incus."
}

# Main command handler
case "$1" in
  launch)
    launch_vm "$2"
    ;;
  ls)
    list_vms
    ;;
  help)
    show_help
    ;;
  *)
    if [ -z "$1" ]; then
      show_help
    else
      # If the command isn't recognized, pass it to incus
      incus "$@"
    fi
    ;;
esac
</code></pre>

<h2 id="using-incus">Using Incus</h2>

<p>As mentioned earlier, I almost exclusively use Incus to get a virtual machine.</p>

<p>E.g. with my script I just run:</p>

<pre><code class="language-bash">vm launch a-vm
</code></pre>

<p>Or with the bare Incus command it’s just as easy:</p>

<pre><code class="language-bash">incus launch images:ubuntu/24.04 a-vm --vm
</code></pre>

<p>Now I can shell into the VM very quickly.</p>

<pre><code class="language-bash">$ incus shell a-vm # or with my script, vm shell a-vm
root@a-vm:~# 
</code></pre>

<p>And you are in a nice little virtual machine that you can install anything you want into.</p>

<h2 id="getting-a-container">Getting a Container</h2>

<p>Writing this post was the first time I used the container functionality of Incus! Getting a container is the default mode of operation, and it’s super easy.</p>

<pre><code class="language-bash">$ incus launch images:ubuntu/22.04 ubuntu-container
# Image is downloaded, and the container is created
Launching ubuntu-container
$ incus ls | grep ubuntu-container
| ubuntu-container | RUNNING | 10.57.7.201 (eth0)           | fd42:af1f:b7c8:a36c:216:3eff:fee9:32e4 (eth0)   | CONTAINER       | 0         |
$ vm shell ubuntu-container
</code></pre>

<p>That is lightning fast. But again, important to note: this is a “system container” and not a “application container”, or in simpler terms, it’s not a docker container. If you have ever used LXC, then you will be right at home.</p>

<blockquote>
  <p>Application containers (as provided by, for example, Docker) package a single process or application. System containers, on the other hand, simulate a full operating system similar to what you would be running on a host or in a virtual machine. You can run Docker in an Incus system container, but you would not run Incus in a Docker application container. - <a href="https://linuxcontainers.org/incus/docs/main/explanation/containers_and_vms/">Incus Docs</a></p>
</blockquote>

<p>You may also want to understand the differences between a virtual machine and a system container:</p>

<blockquote>
  <p>Virtual machines create a virtual version of a physical machine, using hardware features of the host system. The boundaries between the host system and virtual machines is enforced by those hardware features. System containers, on the other hand, use the already running OS kernel of the host system instead of launching their own kernel. If you run several system containers, they all share the same kernel, which makes them faster and more lightweight than virtual machines. - <a href="https://linuxcontainers.org/incus/docs/main/explanation/containers_and_vms/">Incus Docs</a></p>
</blockquote>

<h2 id="why-use-incus">Why Use Incus?</h2>

<p>You can see a list of major features <a href="https://linuxcontainers.org/incus/introduction/#features">here</a> but what I like about it might not be the same as what you like about it.</p>

<ol>
  <li>It’s very fast - There is an agent in the image that makes getting a shell into the VM super fast. The images are also small and download like lightning, at least in my experience.</li>
  <li>It’s easy to manage - Incus has a simple syntax for launching VMs and containers</li>
  <li>Image based - Incus uses images, instead of futzing around with qemu backing files and such</li>
  <li>You use Linux as your workstation and need to easily get a VM, or a system container</li>
</ol>

<p>You can also try it online: <a href="https://linuxcontainers.org/incus/try-it/">https://linuxcontainers.org/incus/try-it/</a></p>

<h2 id="why-wouldnt-you-use-incus">Why Wouldn’t You Use Incus?</h2>

<ol>
  <li>It’s not Docker - it’s a different style of containerization, which many people are not used to.</li>
  <li>It’s relatively new, and a lot of work is being done on it - But on Ubuntu 24.04 it’s easy to install and get started.</li>
  <li>I do have some trouble with outbound access from the VMs and have futzed around with Iptables to get it working, but it’s not as easy as one would think–I expect I’m missing something obvious from the docs.</li>
</ol>

<p>That’s about all I can think of.</p>

<h2 id="pairing-incus-with-my-kubernetes-install-script">Pairing Incus with My Kubernetes Install Script</h2>

<p>FYI - If you create an 8GB VM with 4 CPUS, my <a href="https://github.com/ccollicutt/install-kubernetes">single node Kubernetes install script</a> pairs nicely with Incus, and is often what I use it for.</p>

<h2 id="incus-66-was-just-released">Incus 6.6 Was Just Released</h2>

<p>See <a href="https://discuss.linuxcontainers.org/t/incus-6-6-has-been-released/21762">here</a>. There is also a video overview of the new features <a href="https://www.youtube.com/watch?v=gGBEPtQiiQQ">here</a></p>

<p>Install it, try it out. Have fun easily creating VMs and containers!</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Incus]]></summary></entry><entry><title type="html">Building an Insecure App…on Purpose (So That GenAI Can Fix It)</title><link href="https://serverascode.com/2024/10/02/building-an-insecure-app.html" rel="alternate" type="text/html" title="Building an Insecure App…on Purpose (So That GenAI Can Fix It)" /><published>2024-10-02T00:00:00-04:00</published><updated>2024-10-02T00:00:00-04:00</updated><id>https://serverascode.com/2024/10/02/building-an-insecure-app</id><content type="html" xml:base="https://serverascode.com/2024/10/02/building-an-insecure-app.html"><![CDATA[<h2 id="tldr">tldr;</h2>

<p>tldr; I built an insecure web application (on purpose) for testing LLMs and here it is: <a href="https://github.com/ccollicutt/insecure-nextjs-guestbook">https://github.com/ccollicutt/insecure-nextjs-guestbook</a>.</p>

<h2 id="dealing-with-technical-debt-using-genai">Dealing with Technical Debt using GenAI</h2>

<p>Is cybersecurity largely a technical issue? An engineering issue? It’s difficult to say. Certainly human psychology plays a big part of it, but, then again, we’re building (insecure) software things and putting them out into the world. We write billions of lines of code, and we can’t do that without making mistakes…so there are billions of mistakes too. That code has bugs, it gets worse over time, and is hard (read: expensive) to maintain. It ends up being a technical liability–a security liability. The reality of software development is an important part of the cybersecurity story. Not the whole story, but an important part.</p>

<p>For this line of thinking, the question is, can Generative Artificial Intelligence (GenAI) help us deal with all this overwhelming technical debt? I believe that GenAI can code, and code well enough to help us get rid of technical debt. And what’s more, this ability can be automated and has the potential to be fast–very fast–so it can potentially take care of a lot of technical debt in a short period of time. Now, not everyone may agree with me, but that’s my opinion, and I’m sticking to it!</p>

<p>So if you believe, or can suspend your disbelief, that GenAI can help you deal with technical debt, then you’ll want to test it, just like I do. But how do you test code that generates code?</p>

<p>I’m going to build an insecure web application and then use GenAI to try to fix it.</p>

<h2 id="what-does-insecure-mean">What Does “Insecure” Mean?</h2>

<p>However, building an insecure web application is a bit of a challenge. On the one hand, we have all kinds of technical debt that’s easy to accumulate in the real world, but on the other hand, when we write a new application, the frameworks, libraries, and tools we use are working behind the scenes to keep us as secure as possible, so in some ways it’s a challenge to build an insecure application, at least out of the gate.</p>

<p>And yet I managed to do it. At least partially.</p>

<p>So, what is an insecure web application? What are common examples of insecurity in a web application?</p>

<h2 id="owasp-top-10">OWASP Top 10</h2>

<p>One way to think about web app vulnerabilities is through the <a href="https://owasp.org/www-project-top-ten/">OWASP Top 10</a>.</p>

<p>Here’s the current OWASP Top 10, as of 2021:</p>

<ul>
  <li>A01:2021-Broken Access Control</li>
  <li>A02:2021-Cryptographic Failures</li>
  <li>A03:2021-Injection</li>
  <li>A04:2021-Insecure Design</li>
  <li>A05:2021-Security Misconfiguration</li>
  <li>A06:2021-Vulnerable and Outdated Components</li>
  <li>A07:2021-Identification and Authentication Failures</li>
  <li>A08:2021-Software and Data Integrity Failures</li>
  <li>A09:2021-Security Logging and Monitoring Failures</li>
  <li>A10:2021-Server-Side Request Forgery (SSRF)</li>
</ul>

<p>Let’s look at A01:2021-Broken Access Control, as defined by OWASP:</p>

<ul>
  <li>Violation of the principle of least privilege or deny by default, where access should only be granted for particular capabilities, roles, or users, but is available to anyone.</li>
  <li>Bypassing access control checks by modifying the URL (parameter tampering or force browsing), internal application state, or the HTML page, or by using an attack tool modifying API requests.</li>
  <li>Permitting viewing or editing someone else’s account, by providing its unique identifier (insecure direct object references)</li>
  <li>Accessing API with missing access controls for POST, PUT and DELETE.</li>
  <li>Elevation of privilege. Acting as a user without being logged in or acting as an admin when logged in as a user.</li>
  <li>Metadata manipulation, such as replaying or tampering with a JSON Web Token (JWT) access control token, or a cookie or hidden field manipulated to elevate privileges or abusing JWT invalidation.</li>
  <li>CORS misconfiguration allows API access from unauthorized/untrusted origins.</li>
  <li>Force browsing to authenticated pages as an unauthenticated user or to privileged pages as a standard user.</li>
</ul>

<p>Forced browsing, as an example, sounds fun and technical–but it’s really just about browsing pages you aren’t supposed to know exist, pages that just happen to have additional permissions or access that the average user doesn’t have.</p>

<blockquote>
  <p>Forced browsing is an attack where the aim is to enumerate and access resources that are not referenced by the application, but are still accessible. An attacker can use Brute Force techniques to search for unlinked contents in the domain directory, such as temporary directories and files, and old backup and configuration files. These resources may store sensitive information about web applications and operational systems, such as source code, credentials, internal network addressing, and so on, thus being considered a valuable resource for intruders. - <a href="https://owasp.org/www-community/attacks/Forced_browsing">https://owasp.org/www-community/attacks/Forced_browsing</a></p>
</blockquote>

<p>And, in a similar vein, (typically SQL) injection, as defined by OWASP:</p>

<ul>
  <li>User-supplied data is not validated, filtered, or sanitized by the application.</li>
  <li>Dynamic queries or non-parameterized calls without context-aware escaping are used directly in the interpreter.</li>
  <li>Hostile data is used within object-relational mapping (ORM) search parameters to extract additional, sensitive records.</li>
  <li>Hostile data is directly used or concatenated. The SQL or command contains the structure and malicious data in dynamic queries, commands, or stored procedures.</li>
</ul>

<p>Some of these are more interesting than others, and for some–it’s hard to believe that they are still happening in 2024.</p>

<h2 id="building-an-insecure-web-app">Building an Insecure Web App</h2>

<p><img src="/img/insecure-webapp-guestbook.jpg" alt="img" /></p>

<p>While there are a handful of “webgoat”-style applications that will help you learn about these vulnerabilities, I decided to build my own so that I would know exactly what problems I was introducing - and thus I would know exactly what problems I was trying to fix with GenAI.</p>

<p>I was working on learning NodeJS and NextJS, so I decided to build my insecure web application using those technologies.</p>

<p>A few points:</p>

<ul>
  <li>
    <p>I wanted to make a guestbook app of all things because it would be easy to build, and the fact that anyone should be able to post to it would make it easier to introduce vulnerabilities.</p>
  </li>
  <li>
    <p>I immediately put the clear text authentication into a SQLite database. However, in the real world, no one would put cleartext authentication in a SQLite database–or even use their own authentication system. There are many, many libraries and SaaS services that provide authentication as a service, which is much, much more secure, and that is what people will use. (That is, they’re not as easy to configure, and they’re error-prone, but they’re still much more secure than doing it yourself). I imagine most people building a new web application would either use a third party or <a href="https://next-auth.js.org/">NextAuth</a>.</p>
  </li>
  <li>
    <p>There is an admin user with a default password.</p>
  </li>
</ul>

<pre><code>// Insert admin user if not exists
db.get(`SELECT * FROM users WHERE username = 'admin'`, (err, row) =&gt; {
  if (!row) {
    db.run(`INSERT INTO users (username, password, admin) VALUES ('admin', 'admin', 1)`);
  }
});
</code></pre>

<ul>
  <li>I wanted it to be susceptible to SQL injection–but interestingly, SQLite does a lot of work to prevent that, so I had to do some work to make it vulnerable in terms of using raw queries. For the most part, SQLite just does the right thing, and you have to do some work to make it vulnerable.</li>
</ul>

<pre><code>// Vulnerable to SQL injection
const query = `SELECT * FROM users WHERE username = '${username}' AND password = '${password}'`;
</code></pre>

<ul>
  <li>
    <p>I also added an admin page that was supposed to be protected, but wasn’t.</p>
  </li>
  <li>
    <p>Originally the app didn’t use a sessionID in the URL, but I added that to make the webapp EVEN MORE VULNERABLE. But you don’t see sessionIDs in the wild, so I’m not sure if that’s realistic.</p>
  </li>
</ul>

<p>What I have so far is a webapp that is vulnerable to a number of attacks, including</p>

<ul>
  <li>SQL injection</li>
  <li>Forced browsing</li>
  <li>Session hijacking</li>
  <li>Probably Cross-Site Scripting (XSS)</li>
</ul>

<h2 id="testing-the-vulnerabilities">Testing the Vulnerabilities</h2>

<p>In addition to building the insecure application, we need to test for the presence of these vulnerabilities. So there is also a script to test for them. Please note that this is not an exhaustive list of vulnerabilities, but rather a set of examples meant to be illustrative, and in fact many of them do not work.</p>
<pre><code>$ ./tests.sh 
Usage: ./tests.sh [test_name]

Available tests:
  login                  Test common logins
  sql_injection          Run SQL Injection Test
  drop_table             Drop messages table with SQL Injection
  xss                    Run Cross-Site Scripting (XSS) Test
  insecure_auth          List all users and get admin password via SQL Injection
  sensitive_data         Run Sensitive Data Exposure Test
  security_misconfig     Run Security Misconfiguration Test
  known_vulnerabilities  Run Known Vulnerabilities Test
  insufficient_logging   Run Insufficient Logging &amp; Monitoring Test
  list_tables_and_entries List all tables and entries in the database
  help                   Display this help message
  list_users             List all users in the database
  list_nonexistent_users List all users in the database
  list_tables_and_entries List all tables and entries in the database
  list_nonexistent_users List all users in the database
</code></pre>

<p>Here’s an example of SQL injection:</p>

<pre><code>$ ./tests.sh sql_injection
###################################################
# Running SQL Injection Test to create admin user #
###################################################
Step 1: Attempting SQL injection to create admin user...
SQL Injection Response: {"message":"Login successful","sessionId":"d86976cace3f01e5ae248e037483d70d","isAdmin":true,"redirectUrl":"/?sessionId=d86976cace3f01e5ae248e037483d70d&amp;username=admin' --&amp;isAdmin=true"}

Step 2: Inserting hacker user with admin privileges...

Step 3: Attempting to login as the new admin user 'hacker'...
Login response: {"message":"Login successful","sessionId":"d2cfc602ff3fd33d201d69f0fac9bdd2","isAdmin":true,"redirectUrl":"/?sessionId=d2cfc602ff3fd33d201d69f0fac9bdd2&amp;username=hacker&amp;isAdmin=true"}
User 'hacker' logged in successfully with admin privileges. SQL Injection successful.

Step 4: Checking database for 'hacker' user...
19|hacker|hackpass|1

Step 5: Listing all users in the database...
1|admin|admin|1
2|test|stsdf|0
3|admin|admin123|0
19|hacker|hackpass|1
</code></pre>

<p>Or drop some tables:</p>

<pre><code>$ ./tests.sh drop_table
##############################################################################################################################
# Running SQL Injection to Drop Table. This will attempt to drop the 'messages' table from the database using SQL injection. #
##############################################################################################################################
Logging in as admin to perform SQL Injection to drop the messages table...
Logging in with admin:admin
SessionId: f86bec743b5e8cd60ec886b4a6e9e3b1
IsAdmin: true


./tests.sh: line 143: get_cookie: command not found
Dropping the messages table with SQL Injection...
Response: {"message":"Entry added successfully","result":{}}
Querying the database to check if the messages table still exists...
users
</code></pre>

<p>Super hacker stuff, I know.</p>

<h2 id="building-insecure-applications-is-a-lot-of-work">Building Insecure Applications is a Lot of Work</h2>

<p>After all, getting a bunch of vulnerabilities into an application is a lot of work. It’s not realistic to deal with every example that OWASP provides. Furthermore, real-world scenarios are often <em>much</em> more complicated and <em>much</em>  more technical and subtle. Most of what we focus on in cybersecurity is the problem of aging code and the vulnerabilities that come with it. There is less focus on the vulnerabilities that come from improper use of libraries and frameworks and their configuration, vulnerabilities that are subtle and harder to detect. The web application I’m building is more like using a sledgehammer instead of a scalpel, if you’ll pardon the mixed metaphors.</p>

<p>I also need to do more research on OWASP, other tools like the Atomic Red Team, and what other “webgoat”-style applications are out there and how they work, and what they do best.</p>

<p>Find the code, such as it is, <a href="https://github.com/ccollicutt/insecure-nextjs-guestbook">here</a>.</p>

<h2 id="next-up">Next Up</h2>

<p>In future posts, I’ll look more at this insecure webapp, how to test and execute the exploitable vulnerabilities, as well as how to fix it, if possible, using GenAI and tools like <a href="https://cursor.sh/">Cursor</a>.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[tldr;]]></summary></entry><entry><title type="html">Easily Create a Single Node Kubernetes Cluster</title><link href="https://serverascode.com/2024/08/22/install-kubernetes-script.html" rel="alternate" type="text/html" title="Easily Create a Single Node Kubernetes Cluster" /><published>2024-08-22T00:00:00-04:00</published><updated>2024-08-22T00:00:00-04:00</updated><id>https://serverascode.com/2024/08/22/install-kubernetes-script</id><content type="html" xml:base="https://serverascode.com/2024/08/22/install-kubernetes-script.html"><![CDATA[<p>I’ve been working with Kubernetes for a long time. Too long, actually. So long, in fact, that I don’t really use it much anymore. Kubernetes has won in terms of being the default way to deploy modern applications. At this point, it’s kind of boring, which is great! We want boring infrastructure. Boring works. If you’re writing a new application today, the target is going to be a container, and that container is probably going to run in good old boring Kubernetes.</p>

<p>For quite a while, the last few years, I have had a bunch of Kubernetes clusters running in my basement. I have half a rack there that used to be filled with servers. Then that changed to just running one larger server with a couple hundred gigs of memory, and that one server was running a bunch of Kubernetes clusters. But recently I shut that down. Mainly because it’s summer here in Toronto and that one big server was heating up the basement, and I wasn’t using it that much. I may turn it on again in the winter. Not sure. Anyways…</p>

<p>Yesterday I needed a small k8s cluster. So I used my good old <code>install-kubernetes.sh</code> script to install it onto a VM running on my local workstation.</p>

<h2 id="tldr">tl;dr</h2>

<ul>
  <li>I have a 500 line bash script that installs Kubernetes on Ubuntu 22.04, usually a small VM, 8 gigs of ram, 2-4 CPUs, 40 gigs of disk.</li>
  <li>The script can create a single node “cluster”</li>
  <li>Or you can deploy a bunch of virtual machines and make one a control plane node and the other workers</li>
  <li>It only takes 2 or 3 minutes to get a k8s cluster. Below is a picture of the test I ran in a github action. Of course, github’s infrastructure is blazing fast–the speed of the installation will largely depend on how fast you can download packages to the host.</li>
</ul>

<p><img src="/img/install-k8s-action.png" alt="quick install in a github action" /></p>

<p>There are other single node k8s tools, but I like mine, of course :)</p>

<h2 id="install-kubernetes">Install Kubernetes</h2>

<p>For a year and a half or so–first commit was March of 2023–I’ve had a script that will deploy a Kubernetes cluster into a virtual machine.</p>

<p>That script can be found here:</p>

<ul>
  <li><a href="https://github.com/ccollicutt/install-kubernetes">https://github.com/ccollicutt/install-kubernetes</a></li>
</ul>

<p>I haven’t used it for a while, and so it was actually broken for the last bit because the upstream Kubernetes project changed where the packages for Ubuntu are located. So I just updated the script, like bumped it to Kubernetes 1.31, fixed a few other things, and now it’s good to go again to create either a cluster of Kubernetes instances or, perhaps more useful, a full Kubernetes deployment running in a single virtual machine instance (where the single node is both a control plane node and a worker node).</p>

<h2 id="building-a-single-node-kubernetescluster">Building a Single Node Kubernetes…“Cluster”</h2>

<p>First, get yourself an Ubuntu 22.04 virtual machine with at least 8 gigs of ram and around 40 gigs of disk. I’d probably also give it 4 CPUs.</p>

<pre><code>root@install-k8s-demo:~# source /etc/lsb-release; echo $DISTRIB_RELEASE
22.04
root@install-k8s-demo:~# nproc
4
root@install-k8s-demo:~# free -h
           	total    	used    	free  	shared  buff/cache   available
Mem:       	7.7Gi   	124Mi   	7.5Gi    	17Mi   	111Mi   	7.4Gi
Swap:         	0B      	0B      	0B
root@install-k8s-demo:~# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sda  	8:0	0   40G  0 disk
├─sda1   8:1	0  100M  0 part /boot/efi
└─sda2   8:2	0 39.9G  0 part /
</code></pre>

<p>Then, login to that VM and get a root shell.</p>

<p>Next, grab the install-kubernetes script.</p>

<blockquote>
  <p>NOTE: You’ll need git installed.</p>
</blockquote>

<pre><code>root@install-k8s-demo:~# git clone https://github.com/ccollicutt/install-kubernetes
root@install-k8s-demo:~# cd install-kubernetes
</code></pre>

<p>There will be a few files there:</p>

<pre><code>root@install-k8s-demo:~/install-kubernetes# ls
install-kubernetes.sh  makefile  manifests  README.md
</code></pre>

<p>Then, we simply run the <code>install-kubernetes.sh </code>script BUT using the “-s” option to set it so that it deploys a single node control plane + worker node.</p>

<blockquote>
  <p>NOTE: If you forget the “-s”, it is probably best to recreate the virtual machine and reinstall it. This is not idempotent, or at least it hasn’t been tested that way.</p>
</blockquote>

<pre><code>./install-kubernetes.sh -s
</code></pre>

<p>The output of that will look like:</p>

<pre><code>root@install-k8s-demo:~/install-kubernetes# ./install-kubernetes.sh -s
Starting install...
==&gt; Logging all output to /tmp/install-kubernetes-NMxK9WTKim/install.log
Checking Linux distribution
Disabling swap
Removing packages
Installing required packages
Installing Kubernetes packages
Configuring system
Configuring crictl
Configuring kubelet
Configuring containerd
Installing containerd
Starting services
Configuring control plane node...
Initialising the Kubernetes cluster via Kubeadm
Configuring kubeconfig for root and ubuntu users
Installing Calico CNI
==&gt; Installing Calico tigera-operator
==&gt; Installing Calico custom-resources
Waiting for nodes to be ready...
==&gt; Nodes are ready
Checking Kubernetes version...
==&gt; Client version: v1.31.0
==&gt; Server Version: v1.31.0
==&gt; Requested KUBE_VERSION matches the server version.
Installing metrics server
Configuring as a single node cluster
Configuring as a single node cluster
Deploying test nginx pod
Waiting for all pods to be running...
Install complete!

### Command to add a worker node ###
kubeadm join localhost:6443 --token &lt;redact&gt; --discovery-token-ca-cert-hash sha256:&lt;redact&gt;
</code></pre>

<h2 id="now-you-have-a-kubernetes-cluster">Now You Have a Kubernetes Cluster</h2>

<p>At this point, you can run kubectl and access the local cluster.</p>

<p>There’s a kubeconfig in:</p>

<pre><code>root@install-k8s-demo:~# ls ~/.kube/
cache  config
</code></pre>

<p>And, if there is an ubuntu user on the host, the config will be there too.</p>

<pre><code>root@install-k8s-demo:~# ls /home/ubuntu/.kube/
config
</code></pre>

<p>And we can connect to the “cluster”.</p>

<pre><code>root@install-k8s-demo:~# kubectl get pods -A
NAMESPACE      	NAME                                   	READY   STATUS	RESTARTS   AGE
calico-apiserver   calico-apiserver-78d48b5579-j97lc      	1/1 	Running   0      	4m15s
calico-apiserver   calico-apiserver-78d48b5579-kmcvr      	1/1 	Running   0      	4m15s
calico-system  	calico-kube-controllers-7d868b8f66-fldb5   1/1 	Running   0      	4m45s
calico-system  	calico-node-pqfdn                      	1/1 	Running   0      	4m45s
calico-system  	calico-typha-899c7464d-9vqzg           	1/1 	Running   0      	4m45s
calico-system  	csi-node-driver-vqvnx                  	2/2 	Running   0      	4m36s
kube-system    	coredns-6f6b679f8f-tvtjs               	1/1 	Running   0      	4m49s
kube-system    	coredns-6f6b679f8f-zvcdl               	1/1 	Running   0      	4m49s
kube-system    	etcd-install-k8s-demo                  	1/1 	Running   0      	4m57s
kube-system    	kube-apiserver-install-k8s-demo        	1/1 	Running   0      	4m56s
kube-system    	kube-controller-manager-install-k8s-demo   1/1 	Running   0      	4m57s
kube-system    	kube-proxy-9snr9                       	1/1 	Running   0      	4m49s
kube-system    	kube-scheduler-install-k8s-demo        	1/1 	Running   0      	4m56s
kube-system    	metrics-server-5f94f4d4fd-sg2gh        	1/1 	Running   0      	4m35s
tigera-operator	tigera-operator-b974bcbbb-4sjjz        	1/1 	Running   0      	4m49s
</code></pre>

<h2 id="you-can-deploy-many-worker-nodes-if-you-want">You Can Deploy Many Worker Nodes if You Want</h2>

<p>You could also use this script to deploy a single control plane only node, the standard model for deploying K8s where the control plane is separated, and then create and add as many worker nodes to that control plane as makes sense. However, this script does not orchestrate all of this. You would have to log in to each VM and run the script, set it up as a worker node or a control plane node, and then join the worker nodes to the control plane node using the kubeadm join command. So this is not meant to be some kind of high-level k8s cluster creation orchestration mechanism, no magic here. Of course you can create as large a cluster as you want, you just have to set up each node individually.</p>

<h2 id="some-design-decisions">Some Design Decisions</h2>

<p>If you look at the script, here are some design decisions. It’s using:</p>

<ul>
  <li>Ubuntu Kubernetes packages</li>
  <li>containerd</li>
  <li>Calico as the CNI</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>If you need a throwaway Kubernetes cluster that can be created in an Ubuntu 22.04 VM in a few minutes (like two!) I think this is a nice way to do that. Certainly it works for me.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I’ve been working with Kubernetes for a long time. Too long, actually. So long, in fact, that I don’t really use it much anymore. Kubernetes has won in terms of being the default way to deploy modern applications. At this point, it’s kind of boring, which is great! We want boring infrastructure. Boring works. If you’re writing a new application today, the target is going to be a container, and that container is probably going to run in good old boring Kubernetes.]]></summary></entry></feed>